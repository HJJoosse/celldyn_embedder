{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "#try:\n",
    "#    os.chdir(\"L:\\laupodteam\\AIOS\\Huibert-Jan\\Celldynclustering\\celldyn_embedder\")\n",
    "#except FileNotFoundError:\n",
    "#    os.chdir('C:/Users/Huibert-Jan/Documents/Werk/UMCU/celldyn_embedder')    \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pacmap\n",
    "import umap\n",
    "import trimap\n",
    "\n",
    "#from scipy.stats import chisquare, chi2_contingency, pearsonr\n",
    "#from scipy.stats import kendalltau,spearmanr, weightedtau, theilslopes, wilcoxon, ttest_rel\n",
    "#from scipy.spatial import distance\n",
    "#import dcor\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.manifold import Isomap, MDS, SpectralEmbedding\n",
    "from sklearn.manifold import LocallyLinearEmbedding as LLE, TSNE, smacof, trustworthiness\n",
    "from sklearn.cluster import KMeans, BisectingKMeans, OPTICS, affinity_propagation, AgglomerativeClustering\n",
    "# add GMM\n",
    "from sklearn.mixture import GaussianMixture as GMM, BayesianGaussianMixture as BGMM\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "\n",
    "#from sklearn.metrics import rand_score, adjusted_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, silhouette_score\n",
    "#from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "#from sklearn.cluster import KMeans\n",
    "\n",
    "from hembedder.utils.distance import poincarre_dist, hyperboloid_dist, fractional_distance, Distance\n",
    "from hembedder.utils.quality_metrics import CDEmbeddingPerformance\n",
    "#import numpy.linalg as la\n",
    "#import torch \n",
    "\n",
    "#from numba import njit\n",
    "\n",
    "#import faiss\n",
    "import gc\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pysr import PySRRegressor\n",
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklego.meta import ZeroInflatedRegressor\n",
    "#from lineartree import LinearTreeRegressor, LinearForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor, XGBRFClassifier\n",
    "\n",
    "from typing import List, Tuple, Iterable, Callable, Literal\n",
    "\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import adjusted_rand_score as ARI, normalized_mutual_info_score as NMI\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take class BGMM and extend with a function called bic\n",
    "class BGMM(BGMM):\n",
    "    def _n_parameters(self, X):\n",
    "          \"\"\"Return the number of free parameters in the model.\"\"\"\n",
    "          _, n_features = self.means_.shape\n",
    "          # Number of effective components equals the number of unique labels\n",
    "          n_effect_comp = len(np.unique(self.predict(X)))\n",
    "          #n_effect_comp = self.n_components\n",
    "          if self.covariance_type == 'full':\n",
    "              cov_params = n_effect_comp * n_features * (n_features + 1) / 2.\n",
    "          elif self.covariance_type == 'diag':\n",
    "              cov_params = n_effect_comp * n_features\n",
    "          elif self.covariance_type == 'tied':\n",
    "              cov_params = n_features * (n_features + 1) / 2.\n",
    "          elif self.covariance_type == 'spherical':\n",
    "              cov_params = n_effect_comp\n",
    "          mean_params = n_features * n_effect_comp\n",
    "          return int(cov_params + mean_params + n_effect_comp - 1)\n",
    "\n",
    "    def bic(self, X):\n",
    "        \"\"\"Bayesian information criterion for the current model on the input X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array of shape (n_samples, n_dimensions)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bic : float\n",
    "            The lower the better.\n",
    "        \"\"\"\n",
    "        return (-2 * self.score(X) * X.shape[0] + self._n_parameters(X) * np.log(X.shape[0]))\n",
    "\n",
    "    def aic(self, X):\n",
    "        \"\"\"Akaike information criterion for the current model on the input X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array of shape (n_samples, n_dimensions)\n",
    "+\n",
    "        Returns\n",
    "        -------\n",
    "        aic : float\n",
    "            The lower the better.\n",
    "        \"\"\"\n",
    "        return -2 * self.score(X) * X.shape[0] + 2 * self._n_parameters(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_classification_f1(X, labels):\n",
    "    '''\n",
    "        create a logistic regression classifier to predict cluster labels\n",
    "        , determine the stratified cross-validated F1 score of the model.\n",
    "    '''\n",
    "    # create a logistic regression classifier to predict cluster labels\n",
    "    clf = LogisticRegression(random_state=0, penalty='elasticnet', solver='saga', l1_ratio=0.1,\n",
    "                                multi_class='multinomial', max_iter=5000)\n",
    "\n",
    "    # determine the stratified cross-validated F1 score of the model.\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        clf.fit(X[train_index], labels[train_index])\n",
    "        f1_scores.append(f1_score(labels[test_index], clf.predict(X[test_index]), average='weighted'))\n",
    "\n",
    "    return np.mean(f1_scores), np.std(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to run a clustering algorithm in a bootstrapping fashion\n",
    "# the outcome is a list of clustering models\n",
    "def clustering_bootstrapping(data: pd.DataFrame, \n",
    "                             n_clusters: int=10,\n",
    "                             n_bootstraps: int=100, \n",
    "                             sample_size: int=50000,\n",
    "                             clusterer: str='kmeans',\n",
    "                             align: bool=False,\n",
    "                             **kwargs)-> List[Callable]:\n",
    "    if kwargs.get('n_init', None) is None:\n",
    "        n_init = 10\n",
    "    else:\n",
    "        n_init = kwargs.get('n_init')\n",
    "    \n",
    "    model_list = []\n",
    "    for i in tqdm(range(n_bootstraps)):\n",
    "        # sample data\n",
    "        sample = data.sample(sample_size, replace=True)\n",
    "        # cluster sample\n",
    "        if clusterer == 'kmeans':\n",
    "            if (i==0) | (align==False):\n",
    "                model = KMeans(n_clusters=n_clusters, random_state=123, n_init=n_init)\n",
    "                model.fit(sample)\n",
    "                init_means = model.cluster_centers_\n",
    "            else:\n",
    "                model = KMeans(n_clusters=n_clusters, random_state=123, init=init_means, n_init=n_init)\n",
    "                model.fit(sample)\n",
    "        elif clusterer == 'optics':\n",
    "            model = OPTICS(min_samples=100, n_jobs=-1)\n",
    "            model.fit(sample)\n",
    "        elif clusterer == 'hierarchical':\n",
    "            model = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "            model.fit(sample)\n",
    "        elif clusterer == 'gmm':\n",
    "            if (i==0) | (align==False):\n",
    "                model = GMM(n_components=n_clusters, random_state=123)\n",
    "                model.fit(sample)\n",
    "                init_means = model.means_\n",
    "            else:\n",
    "                model = GMM(n_components=n_clusters, random_state=123, means_init=init_means)\n",
    "                model.fit(sample)\n",
    "        elif clusterer == 'bgmm':\n",
    "            if (i==0) | (align==False):\n",
    "                model = BGMM(n_components=n_clusters, random_state=123, max_iter=500)\n",
    "                model.fit(sample)\n",
    "                init_means = model.mean_prior_\n",
    "            else:\n",
    "                model = BGMM(n_components=n_clusters, random_state=123, mean_prior=init_means, max_iter=500)\n",
    "                model.fit(sample)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown clustering algorithm\")\n",
    "        model_list.append(model)\n",
    "    return model_list\n",
    "    \n",
    "def assign_clusters(data: pd.DataFrame, \n",
    "                    model_list: List[Callable], \n",
    "                    clusterer='kmeans') -> pd.DataFrame:\n",
    "    \n",
    "    # get cluster labels\n",
    "    if clusterer in ['kmeans']:\n",
    "        labels = np.array([model.predict(data) for model in model_list])\n",
    "        # get cluster centers\n",
    "        centers = np.array([model.cluster_centers_ for model in model_list])\n",
    "        # get cluster sizes\n",
    "        sizes = np.array([np.bincount(label, minlength=centers.shape[1]) for label in labels])\n",
    "    elif clusterer in ['gmm', 'bgmm']:\n",
    "        labels = np.array([model.predict(data) for model in model_list])\n",
    "        # get cluster centers\n",
    "        centers = np.array([model.means_ for model in model_list])\n",
    "        # get cluster sizes\n",
    "        sizes = np.array([np.bincount(label, minlength=centers.shape[1]) for label in labels])        \n",
    "    return labels, centers, sizes \n",
    "\n",
    "\n",
    "def distance(v1, v2, metric='euclidean'):\n",
    "    ''' Calculate the distance between two vectors '''\n",
    "    if metric=='euclidean':\n",
    "        return np.linalg.norm(v1 - v2)\n",
    "    elif metric=='cosine':\n",
    "        return 1 - np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    elif metric=='poincarre':\n",
    "        return poincarre_dist(v1, v2)\n",
    "    elif metric=='manhattan':\n",
    "        return np.linalg.norm(v1 - v2, ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "celldyn_full = pd.read_feather(\"L:/laupodteam/AIOS/Bram/data/CellDyn/artifacts/celldyn_FULL_transformed_df_updated.feather\")\n",
    "\n",
    "meas_columns = [c for c in celldyn_full.columns if ('c_b' in c) | (\"COMBO\" in c)]\n",
    "mode_columns = [c for c in celldyn_full.columns if 'c_m' in c]\n",
    "alrt_columns = [c for c in celldyn_full.columns if 'alrt' in c.lower()]\n",
    "c_s_columns = [c for c in celldyn_full.columns if 'c_s_' in c.lower()]\n",
    "celldyn_full.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "celldyn_full = celldyn_full.assign(gender=celldyn_full.gender.map({'M':0, 'F':1}))\n",
    "celldyn_full.dropna(subset=['gender','draw_hour'], axis=0, inplace=True)\n",
    "celldyn_full.rename(columns={'studyid_alle_celldyn':'study_id', 'afname_dt': 'sample_dt'}, inplace=True)\n",
    "celldyn_full.set_index(['study_id', 'sample_dt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "celldyn_emb = pd.read_feather(\"L:\\laupodteam\\AIOS\\Bram\\data/CellDyn/artifacts/umap_euclidean_euclidean_spectral_dims_6_n_n_50_n_epochs_400_densmap_True_embedded_data.feather\")\n",
    "celldyn_emb = celldyn_emb.assign(sex=celldyn_emb.sex.map({'M':0, 'F':1}))\n",
    "celldyn_emb.dropna(subset=['sex','draw_hour'], axis=0, inplace=True)\n",
    "celldyn_emb.set_index(['study_id', 'sample_dt'], inplace=True)\n",
    "celldyn_emb = celldyn_emb.loc[celldyn_full.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_full = celldyn_full.reset_index()[['study_id', 'sample_dt']].drop_duplicates()\n",
    "in_emb = celldyn_emb.reset_index()[['study_id', 'sample_dt']].drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using sparse coding\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature expansion using  symbolic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob metrics\n",
    "\n",
    "* We use the density profiles from HDBSCAN to characterize the blobbiness of the data\n",
    "* We use fuzzy c-means in combination with AUFPC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "sample_size = 100000\n",
    "selection = in_full.sample(sample_size).reset_index(drop=True)\n",
    "\n",
    "kwargs = {\n",
    "    'min_cluster_size': 5, \n",
    "    'min_samples': 15, \n",
    "    'metric': 'manhattan',\n",
    "    'cluster_selection_method':'leaf'    \n",
    "}\n",
    "\n",
    "emb_index = celldyn_emb[celldyn_emb.index.isin(selection.itertuples(index=False))].index.drop_duplicates()\n",
    "full_index = celldyn_full[celldyn_full.index.isin(selection.itertuples(index=False))].index.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(pipeline.named_steps['hdbscan'].probabilities_, bins=100);\n",
    "#pipeline.named_steps['clusterer'].condensed_tree_\\\n",
    "#        .plot(select_clusters=True,selection_palette=sns.color_palette('deep', 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ranker = FunctionTransformer(lambda x: np.argsort(np.argsort(x, axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = celldyn_full.loc[full_index].reset_index().groupby(['study_id', 'sample_dt']).first()\n",
    "df_ = df[meas_columns].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_fitter(df, \n",
    "                scaler: Literal = ['standard', 'minmax', 'power'],\n",
    "                clusterer: Literal = ['kmeans', 'hdbscan', 'optics'],\n",
    "                embedder: Literal = ['pca', 'umap', 'trimap', 'pacmap', 'RAW'],\n",
    "                pre_ranking: bool = True,\n",
    "                n_components = 6,\n",
    "                n_clusters = 10):\n",
    "    '''\n",
    "        in:\n",
    "            df: dataframe with measurements\n",
    "            clusterer: clusterer to use\n",
    "            embedder: embedder to use\n",
    "            pre_ranking: whether or not to use pre-ranking\n",
    "            n_components: number of components to use for embedding\n",
    "            n_clusters: number of clusters to use for clustering\n",
    "        returns fitted pipeline\n",
    "    '''\n",
    "    \n",
    "    if scaler == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler == 'power':\n",
    "        scaler = PowerTransformer()\n",
    "        \n",
    "    ######################################################    \n",
    "    \n",
    "    if clusterer == 'optics':\n",
    "        clusterer = OPTICS(min_samples=15, metric='canberra', n_jobs=-1)\n",
    "    elif clusterer == 'hdbscan':\n",
    "        clusterer = HDBSCAN(min_cluster_size=5, min_samples=15, metric='manhattan', cluster_selection_method='leaf')\n",
    "    elif clusterer == 'kmeans':\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=123)\n",
    "\n",
    "    ######################################################\n",
    "\n",
    "    if embedder == 'pca':\n",
    "        embedder = PCA(n_components=n_components, whiten=False)\n",
    "    elif embedder == 'umap':\n",
    "        embedder = umap.UMAP(n_components=n_components, n_neighbors=500, n_epochs=500,\n",
    "                             metric='manhattan', init='spectral',\n",
    "                             random_state=123, densmap=False, min_dist=0)\n",
    "    elif embedder == 'trimap':\n",
    "        pipeline_emb = clusterer.fit(\n",
    "                        trimap.TRIMAP(n_dims=n_components, n_inliers=12, n_outliers=4, \n",
    "                                      distance='manhattan', n_iters=500, lr=0.09).fit_transform(\n",
    "                            scaler.fit_transform(df)\n",
    "                            )\n",
    "                        )\n",
    "        return pipeline_emb\n",
    "    elif embedder == 'pacmap':\n",
    "        embedder = pacmap.PaCMAP(n_components=n_components, \n",
    "                                     n_neighbors=500, num_iters=500, lr=0.9, \n",
    "                                     apply_pca=False)\n",
    "    elif embedder == 'RAW':\n",
    "        embedder = None\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    if pre_ranking:\n",
    "        scaler = None\n",
    "        ranker = Ranker\n",
    "    \n",
    "    le_pipe_list = [('scaler', scaler)]\n",
    "    le_pipe_list += [('ranker', ranker)] if pre_ranking else []\n",
    "    le_pipe_list += [('embedder', embedder)]\n",
    "    le_pipe_list += [('clusterer', clusterer)]    \n",
    "    le_pipe = Pipeline(le_pipe_list)\n",
    "    le_pipe.fit(df)\n",
    "    \n",
    "    return le_pipe\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bes3\\VIRTUALENVS\\embedder\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline_pca = pipe_fitter(df_, \n",
    "                           scaler='standard', \n",
    "                           clusterer='kmeans',\n",
    "                           embedder='pca', \n",
    "                           pre_ranking=True, \n",
    "                           n_components=2,\n",
    "                           n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_emb = pipe_fitter(df_, \n",
    "                           scaler='standard', \n",
    "                           clusterer='kmeans',\n",
    "                           embedder='umap', \n",
    "                           pre_ranking=True, \n",
    "                           n_components=2,\n",
    "                           n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bes3\\VIRTUALENVS\\embedder\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Xpca = pipeline_pca.named_steps['pca'].transform(df.loc[:, meas_columns])\n",
    "Xemb = pipeline_emb.named_steps['embedder'].embedding_\n",
    "Xorg = df.loc[:, meas_columns].values\n",
    "perfClass = CDEmbeddingPerformance(n_neighbours=500, metric='manhattan', dcor_level=1)\n",
    "\n",
    "rnd_sel = np.random.randint(0,100_000, 4000)\n",
    "plt.plot(perfClass._return_dynamic_distance_correlation(Xpca[rnd_sel], Xorg[rnd_sel], n_bins=80))\n",
    "plt.plot(perfClass._return_dynamic_distance_correlation(Xemb[rnd_sel], Xorg[rnd_sel], n_bins=80))\n",
    "plt.legend(['pca', 'emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.34471773965951363\n",
      "NMI: 0.5157489101070742\n",
      "ARI PCA: 0.27884596936681716\n",
      "NMI PCA: 0.4574945026782052\n",
      "num embedding labels: 10\n",
      "num full labels: 10\n",
      "num pca labels: 10\n"
     ]
    }
   ],
   "source": [
    "# ARI, NMI\n",
    "emb_labels = pipeline_emb.named_steps['clusterer'].labels_\n",
    "#emb_labels = pipeline_emb.labels_\n",
    "\n",
    "full_labels = pipeline_full.named_steps['clusterer'].labels_\n",
    "pca_labels = pipeline_pca.named_steps['clusterer'].labels_\n",
    "\n",
    "print(f\"ARI: {ARI(emb_labels, full_labels)}\")\n",
    "print(f\"NMI: {NMI(emb_labels, full_labels)}\")\n",
    "\n",
    "print(f\"ARI PCA: {ARI(pca_labels, full_labels)}\")\n",
    "print(f\"NMI PCA: {NMI(pca_labels, full_labels)}\")\n",
    "\n",
    "print(f\"num embedding labels: {len(np.unique(emb_labels))}\")\n",
    "print(f\"num full labels: {len(np.unique(full_labels))}\")\n",
    "print(f\"num pca labels: {len(np.unique(pca_labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'ordering_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(ncols\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, nrows\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m12\u001b[39m)) \n\u001b[1;32m----> 3\u001b[0m ordering \u001b[39m=\u001b[39m pipeline_emb\u001b[39m.\u001b[39;49mnamed_steps[\u001b[39m'\u001b[39;49m\u001b[39mclusterer\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mordering_\n\u001b[0;32m      4\u001b[0m reach \u001b[39m=\u001b[39m pipeline_emb\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mclusterer\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreachability_[ordering]\n\u001b[0;32m      5\u001b[0m labels \u001b[39m=\u001b[39m pipeline_emb\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mclusterer\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mlabels_[ordering]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'ordering_'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(20, 12)) \n",
    "\n",
    "ordering = pipeline_emb.named_steps['clusterer'].ordering_\n",
    "reach = pipeline_emb.named_steps['clusterer'].reachability_[ordering]\n",
    "labels = pipeline_emb.named_steps['clusterer'].labels_[ordering]\n",
    "space = np.arange(labels.shape[0])\n",
    "num_categories = len(np.unique(labels))\n",
    "colormap = cm.get_cmap('viridis', num_categories)\n",
    "colors = [colormap(i) for i in range(num_categories)]\n",
    "\n",
    "for klass, color in zip(range(0, num_categories), colors):\n",
    "    Xk = space[labels == klass]\n",
    "    Rk = reach[labels == klass]\n",
    "    ax[0].plot(Xk, Rk, color, alpha=0.8)\n",
    "ax[0].plot(space[labels == -1], reach[labels == -1], \"k.\", alpha=0.3)\n",
    "#ax[0].plot(space, np.full_like(space, 2.0, dtype=float), \"k-\", alpha=0.5)\n",
    "#ax[0].plot(space, np.full_like(space, 0.5, dtype=float), \"k-.\", alpha=0.5)\n",
    "ax[0].set_ylabel(\"Reachability (epsilon distance)\")\n",
    "ax[0].set_xlim(1,15000)\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "\n",
    "ordering = pipeline_full.named_steps['clusterer'].ordering_\n",
    "reach = pipeline_full.named_steps['clusterer'].reachability_[ordering]\n",
    "labels = pipeline_full.named_steps['clusterer'].labels_[ordering]\n",
    "space = np.arange(labels.shape[0])\n",
    "num_categories = len(np.unique(labels))\n",
    "colormap = cm.get_cmap('viridis', num_categories)\n",
    "colors = [colormap(i) for i in range(num_categories)]\n",
    "\n",
    "for klass, color in zip(range(0, num_categories), colors):\n",
    "    Xk = space[labels == klass]\n",
    "    Rk = reach[labels == klass]\n",
    "    ax[1].plot(Xk, Rk, color, alpha=0.3)\n",
    "ax[1].plot(space[labels == -1], reach[labels == -1], \"k.\", alpha=0.3)\n",
    "#ax[1].plot(space, np.full_like(space, 2.0, dtype=float), \"k-\", alpha=0.5)\n",
    "#ax[1].plot(space, np.full_like(space, 0.5, dtype=float), \"k-.\", alpha=0.5)\n",
    "ax[1].set_ylabel(\"Reachability (epsilon distance)\")\n",
    "ax[1].set_xlim(1,15000)\n",
    "ax[1].set_ylim(20,40)\n",
    "\n",
    "fig.suptitle(\"Reachability Plot\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "bclusters = clustering_bootstrapping(celldyn_full[meas_columns], n_clusters=10, n_bootstraps=60, sample_size=10000, clusterer='kmeans', n_init=1, align=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = celldyn_full.sample(10000, replace=True)[meas_columns]\n",
    "labels, centers, sizes = assign_clusters(test_set, bclusters, clusterer='kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import fowlkes_mallows_score, homogeneity_score, homogeneity_completeness_v_measure\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score, adjusted_rand_score, adjusted_mutual_info_score, pair_confusion_matrix\n",
    "\n",
    "cluster_overlap_list = []\n",
    "for i in range(labels.shape[0]):\n",
    "    for j in range(i+1, labels.shape[0]):\n",
    "        cluster_overlap_list.append(fowlkes_mallows_score(labels[i], labels[j]))\n",
    "\n",
    "plt.hist(cluster_overlap_list, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to re-order the cluster labels for each model such that the ordinal similarity between the models is maximized\n",
    "init_sim = np.sum(np.corrcoef(labels))/labels.shape[0]**2\n",
    "print(f\"Initial similarity: {init_sim}\")\n",
    "\n",
    "#  we want to align the cluster id's based on the cluster centers or the cluster assignmnents\n",
    "def align_cluster_assignments(labels: np.ndarray, centers: np.ndarray, method: str='centerwise', base_sel: int=0)-> np.ndarray:\n",
    "    '''\n",
    "        Centerwise, given, 1..N models, we align the 2,N models based on the cluster centers of model 1.\n",
    "        I.e. we find the cluster center in model 2 that is closest to the cluster center in model 1 and assign the cluster id's accordingly\n",
    "    '''\n",
    "    if method == 'centerwise':\n",
    "        base_centers = centers[base_sel]\n",
    "        # find the closest cluster center for each model\n",
    "        closest_centers = [[np.argmin([distance(bv.ravel(), _cv.ravel(), metric='cosine') \n",
    "                                            for _cv in cv]) \n",
    "                                                for bv in base_centers] \n",
    "                                                    for cv in centers[1:]\n",
    "                                                    ]\n",
    "        # now we have the closest cluster centers for each model, we can re-order the labels\n",
    "        aligned_labels = [np.array([closest_centers[i][l] for l in labels[base_sel]]) for i in range(len(closest_centers))]\n",
    "        aligned_centers = [centers[i][closest_centers[i]] for i in range(len(closest_centers))]\n",
    "\n",
    "    '''\n",
    "        TODO:\n",
    "    \tWe want to re-order the cluster labels for each model such that the ordinal similarity between the models is maximized.\n",
    "        We express this similarity with MCC (Matthews correlation coefficient)\n",
    "    '''\n",
    "    # first order the labels from the first model, use the order index\n",
    "    # to order the labels of the other models\n",
    "\n",
    "    # now change the labels of the other models to match the order of the first model\n",
    "\n",
    "\n",
    "    return np.vstack(aligned_labels), np.stack(aligned_centers), closest_centers\n",
    "\n",
    "aligned_labels, aligned_centers, closest_centers = align_cluster_assignments(labels, centers, method='centerwise', base_sel=0)\n",
    "print(f\"Aligned result: {np.sum(np.corrcoef(aligned_labels))/aligned_labels.shape[0]**2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignment = pd.DataFrame(aligned_labels.T, columns=['cluster_assignment_'+str(i) for i in range(aligned_labels.shape[0])])\n",
    "cluster_assignment.index = test_set.index\n",
    "cluster_assignment = cluster_assignment.assign(cluster_entropy=cluster_assignment.apply(lambda x: entropy(np.histogram(x, bins=10, density=True)[0]), axis=1))\n",
    "cluster_assignment = cluster_assignment.assign(median_cluster=cluster_assignment.apply(lambda x: int(np.median(x)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn_emb.loc[cluster_assignment.index].join(cluster_assignment[['cluster_entropy', 'median_cluster']], how='inner')\n",
    "sns.scatterplot(data=plot_df, x='dim_2', y='dim_3', hue='median_cluster', palette='viridis', alpha=0.5, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num = 0\n",
    "for plot_count in range(100):\n",
    "    _v1, _v2 = random.sample(range(0, aligned_centers.shape[2]), 2)\n",
    "    if _v1 != _v2:\n",
    "        v1 = aligned_centers[:, cluster_num, _v1]\n",
    "        v2 = aligned_centers[:, cluster_num, _v2]\n",
    "        plt.scatter(v1, v2, c='r', alpha=0.05)\n",
    "plt.title(f\"Cluster-center spread for cluster {cluster_num}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMI and ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy c-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpcs = []\n",
    "\n",
    "df =celldyn_full[meas_columns] # ['age',  'gender']]\n",
    "#df = celldyn_emb[['dim_1', 'dim_2', 'dim_3', 'dim_4',  'dim_5', 'dim_6']]\n",
    "n_bootstrap = 30\n",
    "sample_count = 50000\n",
    "for n in tqdm(range(n_bootstrap)):\n",
    "    data = df.sample(sample_count)\n",
    "    _idx = data.index\n",
    "    \n",
    "    _fpcs = []\n",
    "    for ncenters, ax in enumerate(range(10),2):\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data.T.values, c=ncenters, m=1.1, \n",
    "                                        error=0.005, maxiter=1000, init=None, seed=123)\n",
    "\n",
    "        # Store fpc values for later\n",
    "        _fpcs.append(fpc)\n",
    "    fpcs.append(_fpcs)\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    plt.plot(np.arange(2, 12), fpcs[i], alpha=0.1, c='b')\n",
    "\n",
    "plt.xlabel(\"Number of centers\")\n",
    "plt.ylabel(\"Fuzzy partition coefficient\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM evaluation\n",
    "\n",
    "* use ```model.aic``` and ```model.bic``` to evaluate GMM\n",
    "* use ```model.score_samples``` to evaluate BGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample data\n",
    "res_list = []\n",
    "n_bootstrap = 10\n",
    "sample_count = 5000\n",
    "n_clusters = 20\n",
    "\n",
    "df =celldyn_full[meas_columns] \n",
    "#df = celldyn_emb[['dim_1', 'dim_2', 'dim_3', 'dim_4',  'dim_5', 'dim_6', 'age', 'sex']]\n",
    "cluster_sizes = []\n",
    "for b in range(n_bootstrap):\n",
    "    data = df.sample(sample_count)\n",
    "    # extract the cluster centers and aic, bic using GMM for 1..10 clusters\n",
    "    \n",
    "    for n in range(2, n_clusters+1):\n",
    "        gmm = GMM(n_components=n, covariance_type='full', random_state=123, max_iter=1000).fit(data)\n",
    "        labels = gmm.predict(data)\n",
    "        cluster_sizes.append(np.bincount(labels))\n",
    "\n",
    "        #centers = gmm.means_\n",
    "        aic = gmm.aic(data)\n",
    "        bic = gmm.bic(data)\n",
    "        silhouette_avg = silhouette_score(data, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data.values, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data.values, labels)\n",
    "        mean_log_likelihood = gmm.score(data)\n",
    "\n",
    "        # only keep the samples that are assigned to clusters with more than 50 samples\n",
    "        # this is to avoid the problem of having too few samples in a cluster\n",
    "        # and thus the cluster classification f1 score is not reliable\n",
    "\n",
    "        f1, f1_std = cluster_classification_f1(data.values, labels)\n",
    "        res_list.append({'bootstrap_round': b, \n",
    "                         'num_cluster': n, \n",
    "                         'AIC': aic, \n",
    "                         'BIC': bic, \n",
    "                         'silhouette_score': silhouette_avg,\n",
    "                         'davies_bouldin_score': davies_bouldin,\n",
    "                         'calinski_harabasz_score': calinski_harabasz,\n",
    "                         'score': mean_log_likelihood,\n",
    "                         'f1': f1,\n",
    "                         'f1_std': f1_std})\n",
    "res_df = pd.DataFrame(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(18, 25))\n",
    "\n",
    "sns.lineplot(data=res_df, x='num_cluster', y='AIC', alpha=0.1, c='b',  ax=ax[0,0])\n",
    "sns.lineplot(data=res_df, x='num_cluster', y='BIC', alpha=0.1, c='b',  ax=ax[0,1])\n",
    "\n",
    "sns.lineplot(data=res_df, x='num_cluster', y='silhouette_score', alpha=0.1, c='b',  ax=ax[1,0])\n",
    "sns.lineplot(data=res_df, x='num_cluster', y='davies_bouldin_score', alpha=0.1, c='b',  ax=ax[1,1])\n",
    "\n",
    "sns.lineplot(data=res_df, x='num_cluster', y='calinski_harabasz_score', alpha=0.1, c='b',  ax=ax[2,0])\n",
    "sns.lineplot(data=res_df, x='num_cluster', y='score', alpha=0.1, c='b',  ax=ax[2,1])\n",
    "\n",
    "sns.lineplot(data=res_df, x='num_cluster', y='f1', alpha=0.1, c='b',  ax=ax[3,0])\n",
    "sns.lineplot(data=res_df, x='num_cluster', y='f1_std', alpha=0.1, c='b',  ax=ax[3,1])\n",
    "\n",
    "fig.suptitle(\"GMM clustering, bootstrap N=10, sample size=5000\")\n",
    "ax[0,0].set_title(\"AIC\")\n",
    "ax[0,1].set_title(\"BIC\")\n",
    "\n",
    "ax[1,0].set_title(\"Silhouette score\")\n",
    "ax[1,1].set_title(\"David Bouldin score\")\n",
    "\n",
    "ax[2,0].set_title(\"Calinski Harabasz score\")\n",
    "ax[2,1].set_title(\"Mean log likelihood\")\n",
    "\n",
    "ax[3,0].set_title(\"F1 score\")\n",
    "ax[3,1].set_title(\"F1 score std\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample data\n",
    "res_list = []\n",
    "n_bootstrap = 20\n",
    "sample_count = 10000\n",
    "n_clusters = 20\n",
    "\n",
    "df =celldyn_full[meas_columns] \n",
    "#df = celldyn_emb[['dim_1', 'dim_2', 'dim_3', 'dim_4',  'dim_5', 'dim_6', 'age', 'sex']]\n",
    "for b in tqdm(range(n_bootstrap)):\n",
    "    data = df.sample(sample_count)\n",
    "    # extract the cluster centers and aic, bic using GMM for 1..10 clusters    \n",
    "    \n",
    "    gmm = BGMM(n_components=n_clusters, covariance_type='full', random_state=123, max_iter=1000).fit(data)\n",
    "    #labels = gmm.predict(data)\n",
    "    #centers = gmm.means_\n",
    "    res_list.append({'bootstrap_round': b, \n",
    "                     'mean_log_likelihood': gmm.score(data)})\n",
    "res_df = pd.DataFrame(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =celldyn_full[meas_columns] \n",
    "data = df.sample(1000)\n",
    "n_comp = 3\n",
    "gmm = BGMM(n_components=n_comp, covariance_type='full', random_state=123, max_iter=1000).fit(data)\n",
    "bgmm_res = gmm.predict_proba(data)\n",
    "AIC = gmm.aic(data)\n",
    "BIC = gmm.bic(data)\n",
    "data['log_likelihood_gmm'] = gmm.score_samples(data)\n",
    "data[[f'cluster_{i}' for i in range(n_comp)]] = bgmm_res\n",
    "res_df = pd.DataFrame(data=bgmm_res, columns=[f'cluster_{i}' for i in range(n_comp)])\n",
    "res_df.index=data.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[f'cluster_{i}' for i in range(n_comp)]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC, BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust = 'cluster_2'\n",
    "plot_df = celldyn_emb.loc[data.index].join(data[['log_likelihood_gmm', clust]], how='inner')\n",
    "sns.scatterplot(data=plot_df[plot_df.log_likelihood_gmm>=0], x='dim_1', y='dim_3', hue=clust, palette='viridis', alpha=0.5, legend=True)\n",
    "sns.scatterplot(data=plot_df[plot_df.log_likelihood_gmm<0], x='dim_1', y='dim_3', color='black', alpha=0.1, legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da1a1f9fee48aeb25414ae45b99f00113784206b411b315deabc951a0f32f6bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
