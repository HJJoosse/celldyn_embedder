{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "#%load_ext autoreload\n",
    "%autoreload 1\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#import modin.pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import joblib\n",
    "\n",
    "os.chdir(\"T:\\\\laupodteam\\\\AIOS\\\\Bram\\\\notebooks\\\\code_dev\\\\celldyn_embedder\\\\sandbox\")\n",
    "#os.chdir(\"/media/UMCU/notebooks/code_dev/celldyn_embedder/sandbox\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "write_to_disk = False\n",
    "read_from_disk = True\n",
    "\n",
    "from numba import jit, njit, float32\n",
    "from functools import lru_cache, cached_property\n",
    "from numpy import linalg as la\n",
    "from collections import defaultdict\n",
    "#import ray\n",
    "#ray.init()\n",
    "\n",
    "from hembedder.utils.distance import poincarre_dist, fractional_distance, hyperboloid_dist, Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@njit(float32(float32[:],float32[:]), fastmath=True)\n",
    "#def poincarre_dist(x,y):\n",
    "#    return np.arccosh(\\\n",
    "#    1 + 2*(\\\n",
    "#        la.norm(x-y,ord = 2)**2/((1-la.norm(x,ord = 2)**2)*(1-la.norm(y,ord = 2)**2))\n",
    "#        )\n",
    "#    )\n",
    "#@njit(float32(float32[:],float32[:], float32), fastmath=True)\n",
    "#def fractional_distance(x, y, f=0.5):\n",
    "#    return np.power(np.abs(np.sum(np.power(x-y, f))), 1/f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpath = \"T:\\laupodteam\\AIOS\\Bram\\data\\CellDyn\\celldyn_cleaned_transformed_imputed_ALL_with_ratios.feather\"\n",
    "#cpath = \"T:\\laupodteam\\AIOS\\Bram\\data\\CellDyn\\celldyn_FULL_transformed_df.feather\"\n",
    "cpath = \"T:\\laupodteam\\AIOS\\Bram\\data\\CellDyn\\celldyn_checked.feather\"\n",
    "celldyn = pd.read_feather(cpath)\n",
    "celldyn.columns = celldyn.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=celldyn, x='age', hue='gender', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=celldyn, x='draw_hour', hue='gender', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=celldyn.loc[celldyn.gender.isin(['M', 'F'])], x='draw_hour', y='age', hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to extract weights based on the gender, the draw hour and the age such that the weighted mean of the age is equal to the day-average of the age for that gender\n",
    "# w = 1+|a_t-a_d|/a_d\n",
    "celldyn = celldyn.assign(weight_vector=np.minimum(celldyn.age/celldyn.age.mean(), celldyn.age.mean()/celldyn.age))\n",
    "weighted_mean = lambda x: np.average(x, weights=celldyn.loc[x.index, 'weight_vector'].values)\n",
    "age_plot = celldyn.groupby(['draw_hour', 'gender']).agg(age_weighted=('age', weighted_mean)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=age_plot[age_plot.gender.isin(['M', 'F'])], x='draw_hour', y='age_weighted', hue='gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patients who have measurements in the evening and during the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_per_patient = celldyn.shape[0]/celldyn.studyid_alle_celldyn.nunique()\n",
    "print(f\"There are on average {meas_per_patient} measurements per patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_patient = pd.DataFrame(celldyn.groupby('studyid_alle_celldyn').size(),  \n",
    "                        columns=['counts_per_patient'])\n",
    "celldyn = celldyn.merge(counts_per_patient.reset_index(), how='left', on='studyid_alle_celldyn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['asp_dt', 'analyzer', 'studyid_alle_celldyn', \n",
    "             'time_to_measurement', 'gender', 'age' , 'afname_dt',\n",
    "             'day_of_year', 'week_of_year', 'year', 'first_day',\n",
    "              'draw_hour', 'meas_hour', 'draw_minute', 'draw_hour_dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,7))\n",
    "sns.violinplot(data=celldyn[celldyn.counts_per_patient<30], x='counts_per_patient', y='draw_hour')\n",
    "plt.axhline(7)\n",
    "plt.axhline(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three blocks: \n",
    "* routine block: from 7AM to 5PM, mostly poli perhaps?\n",
    "* evening block: from 5PM to 12PM\n",
    "* morning block: from 12PM to 7AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celldyn.loc[:,'care_block'] = celldyn.apply(lambda x: 'routine_block'\\\n",
    "                                    if (x['draw_hour']>=7) & (x['draw_hour']<17)\n",
    "                                    else 'evening_block' if (x['draw_hour']>=17) & (x['draw_hour']<=23)\n",
    "                                    else 'morning_block', axis=1\n",
    ")\n",
    "meta_cols.append('care_block')\n",
    "celldyn = celldyn.assign(draw_minute=celldyn.afname_dt.dt.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celldyn = celldyn.assign(draw_hour_dec=celldyn[['draw_hour', 'draw_minute']].apply(lambda x: round(x[0]+x[1]/60, 1), axis=1))\n",
    "meas_cols =[c for c in celldyn.columns if 'c_b_' in c or ':' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to set all values to their 1st and 99th percentile\n",
    "def clip_outliers(df, cols, qL=0.01, qH=0.99):\n",
    "    for col in cols:\n",
    "        df.loc[:,col] = df[col].clip(df[col].quantile(qL), df[col].quantile(qH))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec').c_b_bas.quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_eos.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_neu.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_seg.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "\n",
    "plot_df.rename(columns={'level_1': 'percentile'}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(22,9))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_bas', color='black', ax=ax[0,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_eos', color='black', ax=ax[0,1])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_neu', color='black', ax=ax[1,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_seg', color='black', ax=ax[1,1])\n",
    "\n",
    "ax[0,0].set_xlabel('Hour of the day')\n",
    "ax[0,1].set_xlabel('Hour of the day')\n",
    "ax[1,0].set_xlabel('Hour of the day')\n",
    "ax[1,1].set_xlabel('Hour of the day')\n",
    "\n",
    "plt.suptitle('Hourly variation in granulocytes', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec').c_b_mon.quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_mone.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_lym.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "plot_df.rename(columns={'level_1': 'percentile'}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(22,4))\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_mon', color='black', ax=ax[0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_mone', color='black', ax=ax[1])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_lym', color='black', ax=ax[2])\n",
    "# seg\n",
    "ax[0].set_xlabel('Hour of the day')\n",
    "ax[1].set_xlabel('Hour of the day')\n",
    "ax[2].set_xlabel('Hour of the day')\n",
    "\n",
    "plt.suptitle('Hourly variation in agranulocytes', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec').c_b_retc.quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_rbci.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_irf.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_wbc.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "\n",
    "plot_df.rename(columns={'level_1': 'percentile'}, inplace=True)\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(22,9))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_retc', color='black', ax=ax[0,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_rbci', color='black', ax=ax[0,1])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_irf', color='black', ax=ax[1,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_wbc', color='black', ax=ax[1,1])\n",
    "\n",
    "ax[0,0].set_xlabel('Hour of the day')\n",
    "ax[0,1].set_xlabel('Hour of the day')\n",
    "ax[1,0].set_xlabel('Hour of the day')\n",
    "ax[1,1].set_xlabel('Hour of the day')\n",
    "\n",
    "ax[0,0].set_ylabel('Reticulocytes')\n",
    "ax[0,1].set_ylabel('RBC impedance')\n",
    "ax[1,0].set_ylabel('Immature reticuloctye fraction')\n",
    "ax[1,1].set_ylabel('White blood cell count')\n",
    "\n",
    "plt.suptitle('Hourly variation in red/white blood cells ', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec').c_b_plti.quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_plto.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(22,4))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_plti', color='black', ax=ax[0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_plto', color='black', ax=ax[1])\n",
    "\n",
    "ax[0].set_xlabel('Hour of the day')\n",
    "ax[1].set_xlabel('Hour of the day')\n",
    "\n",
    "ax[0].set_ylabel('PLT impedance')\n",
    "ax[1].set_ylabel('PLT optics')\n",
    "\n",
    "plt.suptitle('Hourly variation in platelets ', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec').c_b_mcv.quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_mch.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_mchc.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_rdw.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "          \n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(22,9))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_mcv', color='black', ax=ax[0,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_mch', color='black', ax=ax[0,1])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_mchc', color='black', ax=ax[1,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_rdw', color='black', ax=ax[1,1])\n",
    "\n",
    "\n",
    "ax[0,0].set_xlabel('Hour of the day')\n",
    "ax[0,1].set_xlabel('Hour of the day')\n",
    "ax[1,0].set_xlabel('Hour of the day')\n",
    "ax[1,1].set_xlabel('Hour of the day')\n",
    "\n",
    "ax[0,0].set_ylabel('Mean corpuscular volume')\n",
    "ax[0,1].set_ylabel('Mean corpuscular hemoglobin')\n",
    "ax[1,0].set_ylabel('Mean corpuscular hemoglobin concentration')\n",
    "ax[1,1].set_ylabel('Red cell distribution width')\n",
    "\n",
    "plt.suptitle('Hourly variation of aggregate blood parameters ', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec').c_b_plti.quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec').c_b_plto.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(22,4))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_plti', color='black', ax=ax[0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='c_b_plto', color='black', ax=ax[1])\n",
    "\n",
    "ax[0].set_xlabel('Hour of the day')\n",
    "ax[1].set_xlabel('Hour of the day')\n",
    "\n",
    "ax[0].set_ylabel('PLT impedance')\n",
    "ax[1].set_ylabel('PLT optics')\n",
    "\n",
    "plt.suptitle('Hourly variation in platelets ', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbc/(retc+irf), neu/seg, lym/mon, wbc/plti, plti/(retc+irf), wbc/(mon+lym), ig/(bas+neu+eos), retc/hb, wbc/rbci, rbci/(retc+irf)\n",
    "\n",
    "celldyn = celldyn.assign(wbc_over_rbc=0.5*celldyn.c_b_wbc/(celldyn.c_b_rbci+celldyn.c_b_rbco))\n",
    "celldyn = celldyn.assign(neu_over_seg=celldyn.c_b_neu/celldyn.c_b_seg)\n",
    "celldyn = celldyn.assign(neu_over_wbc=celldyn.c_b_neu/(celldyn.c_b_wbc-celldyn.c_b_neu))\n",
    "celldyn = celldyn.assign(lym_over_mon=celldyn.c_b_lym/celldyn.c_b_mon)\n",
    "celldyn = celldyn.assign(wbc_over_plt=celldyn.c_b_wbc/celldyn.plt) # plti, plto\n",
    "celldyn = celldyn.assign(plt_over_rbc=0.5*celldyn.plt/(celldyn.c_b_rbci+celldyn.c_b_rbco))\n",
    "celldyn = celldyn.assign(retc_over_hb=celldyn.c_b_retc/celldyn.c_b_hb)\n",
    "celldyn = celldyn.assign(rbc_over_irbc=celldyn.c_b_rbci/(celldyn.c_b_retc+celldyn.c_b_irf))\n",
    "celldyn = celldyn.assign(plt_over_lym=celldyn.plt/celldyn.c_b_lym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbc_over_rbc\n",
    "# neu_over_seg\n",
    "# plt_over_rbc\n",
    "# wbc_over_plt\n",
    "\n",
    "plot_df = celldyn.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec').wbc_over_rbc.quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec').neu_over_seg.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').plt_over_rbc.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').wbc_over_plt.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "          \n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(22,9))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='wbc_over_rbc', color='black', ax=ax[0,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='neu_over_seg', color='black', ax=ax[0,1])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='plt_over_rbc', color='black', ax=ax[1,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='wbc_over_plt', color='black', ax=ax[1,1])\n",
    "\n",
    "\n",
    "ax[0,0].set_xlabel('Hour of the day')\n",
    "ax[0,1].set_xlabel('Hour of the day')\n",
    "ax[1,0].set_xlabel('Hour of the day')\n",
    "ax[1,1].set_xlabel('Hour of the day')\n",
    "\n",
    "ax[0,0].set_ylabel('Leukocyte/erytrocyte ratio')\n",
    "ax[0,1].set_ylabel('Neutrophil/segment ratio')\n",
    "ax[1,0].set_ylabel('Platelet/erytrocyte ratio')\n",
    "ax[1,1].set_ylabel('Leukocyte/platelet ratio')\n",
    "\n",
    "plt.suptitle('Hourly variation of hematology ratios ', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'neu:lym'\n",
    "# 'mon:lym'\n",
    "#  plt_over_lym\n",
    "#  retc_over_hb\n",
    "\n",
    "plot_df = celldyn.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec')['neu:lym'].quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec')['mon:lym'].quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').plt_over_lym.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').retc_over_hb.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "          \n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(22,9))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='neu:lym', color='black', ax=ax[0,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='mon:lym', color='black', ax=ax[0,1])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='plt_over_lym', color='black', ax=ax[1,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='retc_over_hb', color='black', ax=ax[1,1])\n",
    "\n",
    "\n",
    "ax[0,0].set_xlabel('Hour of the day')\n",
    "ax[0,1].set_xlabel('Hour of the day')\n",
    "ax[1,0].set_xlabel('Hour of the day')\n",
    "ax[1,1].set_xlabel('Hour of the day')\n",
    "\n",
    "ax[0,0].set_ylabel('Neutrophil/lymphocyte ratio')\n",
    "ax[0,1].set_ylabel('Monocyte/lymphocyte ratio')\n",
    "ax[1,0].set_ylabel('Platelet/lymphocyte ratio')\n",
    "ax[1,1].set_ylabel('Reticulocyte/hemoglobin ratio')\n",
    "\n",
    "plt.suptitle('Hourly variation of hematology ratios ', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_cols.extend(['wbc_over_rbc', 'neu_over_seg', 'lym_over_mon', 'wbc_over_plt', 'neu_over_wbc',\n",
    "                  'plt_over_rbc', 'retc_over_hb', 'rbc_over_irbc', 'plt_over_lym'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify multi-collinear compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_correlations = []\n",
    "for i in tqdm(range(20)):\n",
    "    feature_correlations.append(celldyn.sample(5000)[meas_cols].corr(method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 3\n",
    "af_clust = AffinityPropagation(random_state=0, affinity='precomputed')\n",
    "af_clust.fit(1-np.exp(w*(1-feature_correlations[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = defaultdict(int)\n",
    "for corss in feature_correlations:\n",
    "    for exemplar in corss.columns[af_clust.cluster_centers_indices_]:\n",
    "        count_dict[exemplar] += 1/len(feature_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_b_phpr</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_mchc</th>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pig</th>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_limn</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_plto</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pdw</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_irf</th>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pmac</th>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_rbcfmn</th>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pimn</th>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "c_b_phpr     1.00\n",
       "c_b_mchc     0.98\n",
       "c_b_pig      0.97\n",
       "c_b_limn     0.96\n",
       "c_b_plto     0.96\n",
       "c_b_pdw      0.94\n",
       "c_b_irf      0.90\n",
       "c_b_pmac     0.86\n",
       "c_b_rbcfmn   0.84\n",
       "c_b_pimn     0.82"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_dict, index=[1]).T.rename(columns={1:'count'}).sort_values('count', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hierarchical clustering to find highly correlated feature-clusters\n",
    "\n",
    "\n",
    "# choose examplars, put the other conntributing features in a dict with the examplar as key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA, FactorAnalysis, NMF, SparseCoder, SparsePCA\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, FunctionTransformer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dimensions = 6\n",
    "# manhattan: 40s, 50.000 samples\n",
    "# poincarre: 4m, 50.000 samples\n",
    "# fractional_distance: 2m, 50.000 samples\n",
    "dist =  fractional_distance #, poincarre_dist, manhattan, hyperboloid_dist\n",
    "reducer = UMAP(n_components=reduced_dimensions, n_neighbors=50, n_jobs=8, min_dist=0, metric=dist, densmap=False)\n",
    "emb_cols = [f'dim_{i}' for i in range(reduced_dimensions)]\n",
    "\n",
    "sample_index = celldyn.dropna(subset=meas_cols).sample(250000).index\n",
    "celldyn_embedded = celldyn.loc[sample_index, meta_cols].copy()\n",
    "reduce_pipe = Pipeline([\n",
    "    #('Drop nan', FunctionTransformer(lambda x: x.dropna(axis=0, how='any'))),\n",
    "    ('Scaling Q', QuantileTransformer(n_quantiles=500, output_distribution='normal', random_state=42)),\n",
    "    ('Embedder', reducer),\n",
    "])\n",
    "reduce_pipe.fit(celldyn.loc[sample_index, meas_cols])\n",
    "celldyn_embedded.loc[:, emb_cols] = reduce_pipe.transform(celldyn.loc[sample_index, meas_cols])\n",
    "celldyn_embedded = celldyn_embedded.assign(normal_prick=celldyn_embedded.draw_hour==8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(celldyn_embedded.sample(10000), x='dim_0', y='dim_2', z='dim_4',\n",
    "                    color='age', size_max=7, opacity=0.15)\n",
    "\n",
    "# tight layout\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn_embedded.sample(250000)\n",
    "plot_df = plot_df.groupby('draw_hour_dec').dim_0.quantile([0.25, 0.5, 0.75]).to_frame().join(\n",
    "          plot_df.groupby('draw_hour_dec').dim_1.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').dim_2.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').dim_3.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').dim_4.quantile([0.25, 0.5, 0.75]).to_frame()).join(\n",
    "          plot_df.groupby('draw_hour_dec').dim_5.quantile([0.25, 0.5, 0.75]).to_frame()).reset_index()\n",
    "\n",
    "          \n",
    "fig, ax = plt.subplots(ncols=3, nrows=2, figsize=(22,12))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='dim_0', color='black', ax=ax[0,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='dim_1', color='black', ax=ax[0,1])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='dim_2', color='black', ax=ax[0,2])\n",
    "\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='dim_3', color='black', ax=ax[1,0])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='dim_4', color='black', ax=ax[1,1])\n",
    "sns.lineplot(data=plot_df, x='draw_hour_dec', y='dim_5', color='black', ax=ax[1,2])\n",
    "\n",
    "ax[0,0].set_xlabel('Hour of the day')\n",
    "ax[0,1].set_xlabel('Hour of the day')\n",
    "ax[0,2].set_xlabel('Hour of the day')\n",
    "ax[1,0].set_xlabel('Hour of the day')\n",
    "ax[1,1].set_xlabel('Hour of the day')\n",
    "ax[1,2].set_xlabel('Hour of the day')\n",
    "\n",
    "ax[0,0].set_ylabel('embedded dimension 0')\n",
    "ax[0,1].set_ylabel('embedded dimension 1')\n",
    "ax[0,2].set_ylabel('embedded dimension 2')\n",
    "\n",
    "ax[1,0].set_ylabel('embedded dimension 3')\n",
    "ax[1,1].set_ylabel('embedded dimension 4')\n",
    "ax[1,2].set_ylabel('embedded dimension 5')\n",
    "\n",
    "plt.suptitle('Hourly variation of embedded values ', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = celldyn_embedded.loc[celldyn_embedded.age.between(0,90)]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=2, figsize=(22,12))\n",
    "\n",
    "sns.lineplot(data=plot_df, x='age', y='dim_0', color='black', ax=ax[0,0])\n",
    "sns.lineplot(data=plot_df, x='age', y='dim_1', color='black', ax=ax[0,1])\n",
    "sns.lineplot(data=plot_df, x='age', y='dim_2', color='black', ax=ax[0,2])\n",
    "\n",
    "sns.lineplot(data=plot_df, x='age', y='dim_3', color='black', ax=ax[1,0])\n",
    "sns.lineplot(data=plot_df, x='age', y='dim_4', color='black', ax=ax[1,1])\n",
    "sns.lineplot(data=plot_df, x='age', y='dim_5', color='black', ax=ax[1,2])\n",
    "\n",
    "ax[0,0].set_xlabel('Age')\n",
    "ax[0,1].set_xlabel('Age')\n",
    "ax[0,2].set_xlabel('Age')\n",
    "ax[1,0].set_xlabel('Age')\n",
    "ax[1,1].set_xlabel('Age')\n",
    "ax[1,2].set_xlabel('Age')\n",
    "\n",
    "ax[0,0].set_ylabel('embedded dimension 0')\n",
    "ax[0,1].set_ylabel('embedded dimension 1')\n",
    "ax[0,2].set_ylabel('embedded dimension 2')\n",
    "\n",
    "ax[1,0].set_ylabel('embedded dimension 3')\n",
    "ax[1,1].set_ylabel('embedded dimension 4')\n",
    "ax[1,2].set_ylabel('embedded dimension 5')\n",
    "\n",
    "plt.suptitle('Age variation of embedded values ', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_reducer = PCA()\n",
    "reduce_pipe = Pipeline([\n",
    "    #('Drop nan', FunctionTransformer(lambda x: x.dropna(axis=0, how='any'))),\n",
    "    ('Scaling Q', QuantileTransformer(n_quantiles=500, output_distribution='normal', random_state=42)),\n",
    "    ('Reduce', PCA_reducer)])\n",
    "reduce_pipe.fit(celldyn.loc[sample_index, meas_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(reduce_pipe.named_steps['Reduce'].explained_variance_ratio_))\n",
    "plt.axhline(0.95, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = 3\n",
    "PCA_reducer = FactorAnalysis(rotation='varimax', n_components=n_comps)\n",
    "reduce_pipe = Pipeline([\n",
    "    #('Drop nan', FunctionTransformer(lambda x: x.dropna(axis=0, how='any'))),\n",
    "    ('Scaling Q', QuantileTransformer(n_quantiles=500, output_distribution='normal', random_state=42)),\n",
    "    ('Reduce', PCA_reducer)])\n",
    "reduce_pipe.fit(celldyn.loc[sample_index, meas_cols])\n",
    "\n",
    "FA_weights = pd.DataFrame(data=reduce_pipe.named_steps['Reduce'].components_, columns=meas_cols, index=['comp_{}'.format(i) for i in range(n_comps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_b_wbc</th>\n",
       "      <th>c_b_wvf</th>\n",
       "      <th>c_b_neu</th>\n",
       "      <th>c_b_seg</th>\n",
       "      <th>c_b_bnd</th>\n",
       "      <th>c_b_ig</th>\n",
       "      <th>c_b_lym</th>\n",
       "      <th>c_b_lyme</th>\n",
       "      <th>c_b_vlym</th>\n",
       "      <th>c_b_mon</th>\n",
       "      <th>...</th>\n",
       "      <th>neu:nrbc</th>\n",
       "      <th>wbc_over_rbc</th>\n",
       "      <th>neu_over_seg</th>\n",
       "      <th>lym_over_mon</th>\n",
       "      <th>wbc_over_plt</th>\n",
       "      <th>neu_over_wbc</th>\n",
       "      <th>plt_over_rbc</th>\n",
       "      <th>retc_over_hb</th>\n",
       "      <th>rbc_over_irbc</th>\n",
       "      <th>plt_over_lym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp_0</th>\n",
       "      <td>0.215799</td>\n",
       "      <td>-0.205791</td>\n",
       "      <td>0.238170</td>\n",
       "      <td>0.148213</td>\n",
       "      <td>1.598315</td>\n",
       "      <td>1.694898</td>\n",
       "      <td>-0.124289</td>\n",
       "      <td>-0.131396</td>\n",
       "      <td>0.060746</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120689</td>\n",
       "      <td>0.244651</td>\n",
       "      <td>2.150929</td>\n",
       "      <td>-0.188384</td>\n",
       "      <td>0.267367</td>\n",
       "      <td>0.217237</td>\n",
       "      <td>-0.075389</td>\n",
       "      <td>0.052099</td>\n",
       "      <td>-0.054408</td>\n",
       "      <td>-0.011369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp_1</th>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.038191</td>\n",
       "      <td>-0.037168</td>\n",
       "      <td>-0.033661</td>\n",
       "      <td>-0.097529</td>\n",
       "      <td>-0.077577</td>\n",
       "      <td>0.185599</td>\n",
       "      <td>0.193665</td>\n",
       "      <td>-0.034965</td>\n",
       "      <td>0.061773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040311</td>\n",
       "      <td>-0.017763</td>\n",
       "      <td>-0.101643</td>\n",
       "      <td>0.097947</td>\n",
       "      <td>-0.112147</td>\n",
       "      <td>-0.159307</td>\n",
       "      <td>0.103847</td>\n",
       "      <td>-0.024668</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>-0.047375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp_2</th>\n",
       "      <td>-0.378719</td>\n",
       "      <td>-0.293683</td>\n",
       "      <td>-0.680559</td>\n",
       "      <td>-0.694372</td>\n",
       "      <td>-0.156038</td>\n",
       "      <td>-0.023206</td>\n",
       "      <td>0.613455</td>\n",
       "      <td>0.608562</td>\n",
       "      <td>0.513392</td>\n",
       "      <td>-0.123026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630497</td>\n",
       "      <td>-0.424976</td>\n",
       "      <td>-0.021709</td>\n",
       "      <td>0.656281</td>\n",
       "      <td>-0.262412</td>\n",
       "      <td>-0.924957</td>\n",
       "      <td>-0.140574</td>\n",
       "      <td>-0.164959</td>\n",
       "      <td>0.159299</td>\n",
       "      <td>-0.603898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         c_b_wbc   c_b_wvf   c_b_neu   c_b_seg   c_b_bnd    c_b_ig   c_b_lym  \\\n",
       "comp_0  0.215799 -0.205791  0.238170  0.148213  1.598315  1.694898 -0.124289   \n",
       "comp_1  0.012981  0.038191 -0.037168 -0.033661 -0.097529 -0.077577  0.185599   \n",
       "comp_2 -0.378719 -0.293683 -0.680559 -0.694372 -0.156038 -0.023206  0.613455   \n",
       "\n",
       "        c_b_lyme  c_b_vlym   c_b_mon  ...  neu:nrbc  wbc_over_rbc  \\\n",
       "comp_0 -0.131396  0.060746  0.112546  ...  0.120689      0.244651   \n",
       "comp_1  0.193665 -0.034965  0.061773  ... -0.040311     -0.017763   \n",
       "comp_2  0.608562  0.513392 -0.123026  ... -0.630497     -0.424976   \n",
       "\n",
       "        neu_over_seg  lym_over_mon  wbc_over_plt  neu_over_wbc  plt_over_rbc  \\\n",
       "comp_0      2.150929     -0.188384      0.267367      0.217237     -0.075389   \n",
       "comp_1     -0.101643      0.097947     -0.112147     -0.159307      0.103847   \n",
       "comp_2     -0.021709      0.656281     -0.262412     -0.924957     -0.140574   \n",
       "\n",
       "        retc_over_hb  rbc_over_irbc  plt_over_lym  \n",
       "comp_0      0.052099      -0.054408     -0.011369  \n",
       "comp_1     -0.024668       0.028633     -0.047375  \n",
       "comp_2     -0.164959       0.159299     -0.603898  \n",
       "\n",
       "[3 rows x 119 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FA_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_reducer = NMF(l1_ratio=1, max_iter=2000, n_components=32)\n",
    "reduce_pipe = Pipeline([\n",
    "    #('Drop nan', FunctionTransformer(lambda x: x.dropna(axis=0, how='any'))),\n",
    "    ('Scaling Q', QuantileTransformer(n_quantiles=500, output_distribution='uniform', random_state=42)),\n",
    "    ('Reduce', NMF_reducer)])\n",
    "reduce_pipe.fit(celldyn.loc[sample_index, meas_cols])\n",
    "\n",
    "NMF_weights = pd.DataFrame(data=reduce_pipe.named_steps['Reduce'].components_, columns=meas_cols, index=['comp_{}'.format(i) for i in range(len(meas_cols))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_reducer.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_weights.sum(axis=0).sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sPCA_reducer = SparsePCA(method='lars', max_iter=1500)\n",
    "reduce_pipe = Pipeline([\n",
    "    #('Drop nan', FunctionTransformer(lambda x: x.dropna(axis=0, how='any'))),\n",
    "    #('Scaling Q', QuantileTransformer(n_quantiles=100, output_distribution='normal', random_state=123)),\n",
    "    ('Scaling S', StandardScaler()),\n",
    "    ('Reduce', sPCA_reducer)])\n",
    "reduce_pipe.fit(celldyn.loc[sample_index, meas_cols])\n",
    "\n",
    "sPCA_weights = pd.DataFrame(data=reduce_pipe.named_steps['Reduce'].components_, columns=meas_cols, index=['comp_{}'.format(i) for i in range(len(meas_cols))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sPCA_weights.columns[(sPCA_weights!=0).sum(axis=0)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt =  QuantileTransformer(n_quantiles=50, output_distribution='normal', random_state=123)\n",
    "sparse_coded_celldyn = SparseCoder(dictionary=qt.fit_transform(celldyn.loc[sample_index, meas_cols].T.values))\\\n",
    "                                                .fit_transform(celldyn.loc[sample_index, meas_cols].T.values)\n",
    "sCoded_recon = pd.DataFrame(data=sparse_coded_celldyn, columns=meas_cols, index=['comp_{}'.format(i) for i in range(len(meas_cols))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, matthews_corrcoef\n",
    "\n",
    "import dcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how important is each component in reconstructing the original data\n",
    "# - sub sample\n",
    "#   -- determine the distance matrix between the samples on the basis of the original components\n",
    "#   -- randomly permute the components and retry\n",
    "\n",
    "def get_distance(X: np.array)-> np.array:\n",
    "    return pdist(X, metric='cityblock')\n",
    "\n",
    "def get_rank(D)-> np.array:\n",
    "    return np.argsort(D)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def permute_vector(l=1000, n=0):\n",
    "    return np.random.permutation(l)\n",
    "\n",
    "def get_permuted_rank(X, n_perm=10):\n",
    "    num_features = X.shape[1]\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    perm_vectors = [permute_vector(l=num_samples, n=n) for n in range(n_perm)]\n",
    "\n",
    "    res_array = []    \n",
    "    for d in range(num_features):\n",
    "        sub_list = []\n",
    "        for n in range(n_perm):\n",
    "            X_perm = X.copy()\n",
    "            X_perm[:, d] = X[perm_vectors[n], d]\n",
    "            rank_vector = get_rank(get_distance(X_perm))\n",
    "            sub_list.append(rank_vector)\n",
    "        res_array.append(sub_list)\n",
    "    return res_array\n",
    "\n",
    "def get_perturbed_rank(X, n_pert=10):\n",
    "    num_features = X.shape[1]\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    stats_list = []\n",
    "    for d in range(num_features):\n",
    "        stats_list.append((np.mean(X[:, d]), np.std(X[:, d])))\n",
    "\n",
    "    res_array = []    \n",
    "    for d in range(num_features):\n",
    "        sub_list = []\n",
    "        for n in range(n_pert):\n",
    "            perburbation_vector = np.random.normal(loc=0, scale=2*stats_list[d][1], size=num_samples)\n",
    "            X_perb = X.copy()\n",
    "            X_perb[:, d] = X[:, d] + perburbation_vector\n",
    "            rank_vector = get_rank(get_distance(X_perb))\n",
    "            sub_list.append(rank_vector)\n",
    "        res_array.append(sub_list)\n",
    "    return res_array\n",
    "\n",
    "def rank_match(v1,v2):\n",
    "    return np.sum(v1-v2)/len(v1)\n",
    "\n",
    "def repeated_agreement_metric(v1, v2, num_rounds=100, num_per_round=100):\n",
    "    scores = []\n",
    "    for _ in range(num_rounds):\n",
    "        batch = np.random.choice(len(v1), size=num_per_round, replace=True)\n",
    "        score = cohen_kappa_score(v1[batch], v2[batch])\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "def compare_rank_with_original(X, rank_metric='correlation', n_perm=10, n_pert=10, how='permutation'):\n",
    "    orank = get_rank(get_distance(X))\n",
    "\n",
    "    if how == 'permutation':\n",
    "        changed_ranks = get_permuted_rank(X, n_perm=n_perm)\n",
    "    elif how== 'perturbation':\n",
    "        changed_ranks = get_perturbed_rank(X, n_pert=n_pert)\n",
    "    else:\n",
    "        raise ValueError('how should be either permutation or perturbation')\n",
    "\n",
    "    # rank-distance\n",
    "    res = []\n",
    "    for d in range(X.shape[1]):\n",
    "        sub_res = []\n",
    "        for prank in changed_ranks[d]:\n",
    "            sub_res.append(repeated_agreement_metric(orank.ravel(), prank.ravel()))\n",
    "        res.append(sub_res)\n",
    "    return res\n",
    "\n",
    "def get_permuted_distance_correlation(X, n_perm=10):\n",
    "    num_features = X.shape[1]\n",
    "    num_samples = X.shape[0]\n",
    "    res = []\n",
    "    for d in tqdm(range(num_features)):\n",
    "        sub_list = []\n",
    "        for n in range(n_perm):\n",
    "            X_perm = X.copy()\n",
    "            X_perm[:, d] = X[permute_vector(l=num_samples, n=n), d]\n",
    "            sub_list.append(dcor.distance_correlation(X, X_perm))\n",
    "        res.append(sub_list)\n",
    "    return res\n",
    "\n",
    "def get_perturbed_distance_correlation(X, n_perm=10):\n",
    "    num_features = X.shape[1]\n",
    "    num_samples = X.shape[0]\n",
    "        \t\n",
    "    stats_list = []\n",
    "    for d in range(num_features):\n",
    "        stats_list.append((np.mean(X[:, d]), np.std(X[:, d])))\n",
    "\n",
    "    res = []\n",
    "    for d in tqdm(range(num_features)):\n",
    "        sub_list = []\n",
    "        for n in range(n_perm):\n",
    "            perburbation_vector = np.random.normal(loc=1, scale=4*stats_list[d][1]/np.abs(stats_list[d][0]), size=num_samples)\n",
    "            X_perm = X.copy()\n",
    "            X_perm[:, d] = X[:, d] * perburbation_vector\n",
    "            dist = dcor.distance_correlation(X, X_perm)\n",
    "            sub_list.append(dist)\n",
    "        res.append(sub_list)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_perm = 5\n",
    "np_pert = 5\n",
    "sample_size = 1000\n",
    "rank_results = compare_rank_with_original(QuantileTransformer(output_distribution='normal', n_quantiles=100)\\\n",
    "                            .fit_transform(celldyn.dropna().sample(sample_size).loc[:, meas_cols].values), n_perm=np_perm, n_pert=np_pert, how='perturbation')\n",
    "rank_results_df = pd.DataFrame(rank_results, index=meas_cols, columns=[f'round_{i}' for i in range(np_perm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_perm = 100\n",
    "dist_results = get_perturbed_distance_correlation(QuantileTransformer(output_distribution='normal', n_quantiles=100).fit_transform(celldyn.dropna().sample(sample_size).loc[:, meas_cols].values), n_perm=np_perm)\n",
    "dist_results_df = pd.DataFrame(dist_results, index=meas_cols, columns=[f'round_{i}' for i in range(np_perm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_results_df.mean(axis=1).sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_results_df.mean(axis=1).sort_values(ascending=False)[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concrete_autoencoder import ConcreteAutoencoderFeatureSelector\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = QuantileTransformer(output_distribution='normal', n_quantiles=250).fit_transform(celldyn.dropna().sample(100000).loc[:, meas_cols].values)\n",
    "\n",
    "num_rounds = 100\n",
    "feature_selection = []\n",
    "for _ in tqdm(range(num_rounds)):\n",
    "    x_train, x_test, _, _ = train_test_split(X, X, test_size=0.2, random_state=None)\n",
    "    x_train = np.reshape(x_train, (len(x_train), -1))\n",
    "    x_test = np.reshape(x_test, (len(x_test), -1))\n",
    "\n",
    "    def decoder(x):\n",
    "        x = Dense(512)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(512)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(X.shape[1])(x)\n",
    "        return x\n",
    "\n",
    "    selector = ConcreteAutoencoderFeatureSelector(K = 32, output_function = decoder, num_epochs = 450)\n",
    "\n",
    "    selector.fit(x_train, x_train, x_test, x_test)\n",
    "    feature_selection.append(np.array(meas_cols)[selector.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = defaultdict(int)\n",
    "\n",
    "for i in feature_selection:\n",
    "    for j in i:\n",
    "        count_dict[j] += 1/len(feature_selection)\n",
    "        \n",
    "    presence_df = pd.DataFrame(count_dict, index=[0]).T.sort_values(by=0, ascending=False).rename(columns={0:'presence'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_b_phpr</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_mchc</th>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pig</th>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_limn</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_plto</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pdw</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_irf</th>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pmac</th>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_rbcfmn</th>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pimn</th>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_ht</th>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_namn</th>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_hdw</th>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_npmn</th>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blst:vlym</th>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_nicv</th>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_rdw</th>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_lyme</th>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_b_pbnd</th>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retc_over_hb</th>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              presence\n",
       "c_b_phpr          1.00\n",
       "c_b_mchc          0.98\n",
       "c_b_pig           0.97\n",
       "c_b_limn          0.96\n",
       "c_b_plto          0.96\n",
       "c_b_pdw           0.94\n",
       "c_b_irf           0.90\n",
       "c_b_pmac          0.86\n",
       "c_b_rbcfmn        0.84\n",
       "c_b_pimn          0.82\n",
       "c_b_ht            0.80\n",
       "c_b_namn          0.79\n",
       "c_b_hdw           0.75\n",
       "c_b_npmn          0.72\n",
       "blst:vlym         0.70\n",
       "c_b_nicv          0.62\n",
       "c_b_rdw           0.62\n",
       "c_b_lyme          0.61\n",
       "c_b_pbnd          0.59\n",
       "retc_over_hb      0.59"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presence_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/bwohlberg/sporco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51a0a984460df69ea8ef0d6fc0c7e856972b26960206abd6058f9a5bb0251c26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
