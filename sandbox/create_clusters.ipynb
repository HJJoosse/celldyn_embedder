{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "#try:\n",
    "#    os.chdir(\"L:\\laupodteam\\AIOS\\Huibert-Jan\\Celldynclustering\\celldyn_embedder\")\n",
    "#except FileNotFoundError:\n",
    "#    os.chdir('C:/Users/Huibert-Jan/Documents/Werk/UMCU/celldyn_embedder')    \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import pacmap\n",
    "import umap\n",
    "#import trimap\n",
    "\n",
    "#from scipy.stats import chisquare, chi2_contingency, pearsonr\n",
    "#from scipy.stats import kendalltau,spearmanr, weightedtau, theilslopes, wilcoxon, ttest_rel\n",
    "#from scipy.spatial import distance\n",
    "#import dcor\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.manifold import Isomap, MDS, SpectralEmbedding\n",
    "from sklearn.manifold import LocallyLinearEmbedding as LLE, TSNE, smacof, trustworthiness\n",
    "from sklearn.cluster import KMeans, OPTICS, affinity_propagation, AgglomerativeClustering\n",
    "# add GMM\n",
    "from sklearn.mixture import GaussianMixture as GMM, BayesianGaussianMixture as BGMM\n",
    "\n",
    "#from sklearn.metrics import rand_score, adjusted_mutual_info_score, adjusted_rand_score\n",
    "#from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
    "#from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "#from sklearn.cluster import KMeans\n",
    "\n",
    "from hembedder.utils.distance import poincarre_dist, hyperboloid_dist, fractional_distance, Distance\n",
    "#from hembedder.utils.quality_metrics import CDEmbeddingPerformance\n",
    "#import numpy.linalg as la\n",
    "#import torch \n",
    "\n",
    "#from numba import njit\n",
    "\n",
    "#import faiss\n",
    "import gc\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pysr import PySRRegressor\n",
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklego.meta import ZeroInflatedRegressor\n",
    "from lineartree import LinearTreeRegressor, LinearForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor, XGBRFClassifier\n",
    "\n",
    "from typing import List, Tuple, Iterable, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celldyn_full = pd.read_feather(\"L:\\laupodteam\\AIOS\\Bram\\data\\CellDyn\\\\artifacts\\celldyn_FULL_transformed_miceforest100_df.feather\")\n",
    "meas_columns = [c for c in celldyn_full.columns if ('c_b' in c) | (\"COMBO\" in c)]\n",
    "mode_columns = [c for c in celldyn_full.columns if 'c_m' in c]\n",
    "alrt_columns = [c for c in celldyn_full.columns if 'alrt' in c.lower()]\n",
    "c_s_columns = [c for c in celldyn_full.columns if 'c_s_' in c.lower()]\n",
    "celldyn_full.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "celldyn_full = celldyn_full.assign(gender=celldyn_full.gender.map({'M':0, 'F':1}))\n",
    "celldyn_full.dropna(subset=['gender','draw_hour'], axis=0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to run a clustering algorithm in a bootstrapping fashion\n",
    "# the outcome is a list of clustering models\n",
    "def clustering_bootstrapping(data: pd.DataFrame, \n",
    "                             n_clusters: int=10,\n",
    "                             n_bootstraps: int=100, \n",
    "                             sample_size: int=50000,\n",
    "                             clusterer: str='kmeans')-> List[Callable]:\n",
    "    \n",
    "    model_list = []\n",
    "    for i in tqdm(range(n_bootstraps)):\n",
    "        # sample data\n",
    "        sample = data.sample(sample_size, replace=True)\n",
    "        # cluster sample\n",
    "        if clusterer == 'kmeans':\n",
    "            model = KMeans(n_clusters=n_clusters, random_state=123)\n",
    "        elif clusterer == 'optics':\n",
    "            model = OPTICS(min_samples=100, n_jobs=-1)\n",
    "        elif clusterer == 'hierarchical':\n",
    "            model = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "        elif clusterer == 'gmm':\n",
    "            model = GMM(n_components=n_clusters, random_state=123)\n",
    "        elif clusterer == 'bgmm':\n",
    "            model = BGMM(n_components=n_clusters, random_state=123)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown clustering algorithm\")\n",
    "        model.fit(sample)\n",
    "        model_list.append(model)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclusters = clustering_bootstrapping(celldyn_full[meas_columns], n_clusters=10, n_bootstraps=10, sample_size=50000, clusterer='gmm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = celldyn_full.sample(10000, replace=True)[meas_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(data: pd.DataFrame, \n",
    "                    model_list: List[Callable], \n",
    "                    clusterer='kmeans') -> pd.DataFrame:\n",
    "    \n",
    "    # get cluster labels\n",
    "    if clusterer in ['kmeans']:\n",
    "        labels = np.array([model.predict(data) for model in model_list])\n",
    "        # get cluster centers\n",
    "        centers = np.array([model.cluster_centers_ for model in model_list])\n",
    "        # get cluster sizes\n",
    "        sizes = np.array([np.bincount(label, minlength=centers.shape[1]) for label in labels])\n",
    "    elif clusterer in ['gmm']:\n",
    "        labels = np.array([model.predict(data) for model in model_list])\n",
    "        # get cluster centers\n",
    "        centers = np.array([model.means_ for model in model_list])\n",
    "        # get cluster sizes\n",
    "        sizes = np.array([np.bincount(label, minlength=centers.shape[1]) for label in labels])        \n",
    "    return labels, centers, sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, centers, sizes = assign_clusters(test_set, bclusters, clusterer='gmm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to re-order the cluster labels for each model such that the ordinal similarity between the models is maximized\n",
    "init_sim = np.sum(np.corrcoef(labels))/labels.shape[0]**2\n",
    "print(f\"Initial similarity: {init_sim}\")\n",
    "\n",
    "\n",
    "#  we want to align the cluster id's based on the cluster centers or the cluster assignmnents\n",
    "def align_cluster_assignments(labels: np.ndarray, centers: np.ndarray, method: str='centerwise')-> np.ndarray:\n",
    "    '''\n",
    "        Centerwise, given, 1..N models, we align the 2,N models based on the cluster centers of model 1.\n",
    "        I.e. we find the cluster center in model 2 that is closest to the cluster center in model 1 and assign the cluster id's accordingly\n",
    "    '''\n",
    "    \n",
    "\n",
    "\n",
    "    '''\n",
    "    \tWe want to re-order the cluster labels for each model such that the ordinal similarity between the models is maximized.\n",
    "        We express this similarity with MCC (Matthews correlation coefficient)\n",
    "    '''\n",
    "    # first order the labels from the first model, use the order index\n",
    "    # to order the labels of the other models\n",
    "\n",
    "    # now change the labels of the other models to match the order of the first model\n",
    "\n",
    "\n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
