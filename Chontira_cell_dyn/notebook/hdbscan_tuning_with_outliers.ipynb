{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"T:/laupodteam/AIOS/Chontira/CellDynClustering\")\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import pandas as pd\n",
    "import hdbscan\n",
    "from evaluation.fast_dunn_index import dunn_fast\n",
    "from data.load_data import *\n",
    "import ast\n",
    "from graphic_stuffs import *\n",
    "import pickle\n",
    "from evaluation.hyperparameter_optimization import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Evaluators\n",
    "\n",
    "evaluators= {'silhouette_score': silhouette_score,\n",
    "            'davies_bouldin_score': davies_bouldin_score,\n",
    "            'dunn_fast': dunn_fast}\n",
    "\n",
    "## data loading\n",
    "dm6_with_labels = pd.read_feather(\"data/embedded_celldyn_ALL_nn50_ndim6_w_labels_.feather\")\n",
    "others_labels = dm6_with_labels.loc[:,dm6_with_labels.columns.isin(['sex', 'age','study_id', 'analysis_dt', 'sample_dt'])]\n",
    "dm6 = load_data().set_df(dm6_with_labels.iloc[:, 0:6]).get_x_from_df(contain_y=False)\n",
    "\n",
    "##order of sorting results\n",
    "ascending = [False,True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples': [5, 10, 15, 20, 25], 'min_cluster_size': [2, 5, 10, 20], 'cluster_selection_epsilon': [0, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0], 'cluster_selection_method': ('eom', 'leaf'), 'metric': ('euclidean', 'manhattan', 'mahalanobis')}\n",
      "{'min_samples': [5], 'min_cluster_size': [2, 5], 'cluster_selection_epsilon': [0.1, 0.2, 0.4, 0.6, 0.8, 1.0], 'cluster_selection_method': ('eom', 'leaf'), 'metric': ('manhattan', 'mahalanobis', 'euclidean')}\n"
     ]
    }
   ],
   "source": [
    "## Paramter set for tuning of HDBSCAN with outliers\n",
    "f = open('models/hdbscan_param_grid.pickle', 'rb')\n",
    "param_grid_full = pickle.load(f)\n",
    "f.close()\n",
    "print(param_grid_full)\n",
    "\n",
    "f = open('models/hdbscan_param_grid_subset.pickle', 'rb')\n",
    "param_grid_subset = pickle.load(f)\n",
    "f.close()\n",
    "print(param_grid_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 10% done.\n",
      "Around 20% done.\n",
      "Around 30% done.\n",
      "Around 40% done.\n",
      "Around 50% done.\n",
      "Around 60% done.\n",
      "Around 70% done.\n",
      "Around 80% done.\n",
      "Around 90% done.\n",
      "Hyperpameter tuning is done and the best scores are:\n",
      "silhouette_score        0.282535\n",
      "davies_bouldin_score     2.87282\n",
      "dunn_fast               0.009253\n",
      "Name: 0, dtype: object\n",
      "Number of unique labels 3\n",
      "with parameter: {'min_samples': 15, 'min_cluster_size': 5, 'cluster_selection_epsilon': 1.0, 'cluster_selection_method': 'eom', 'metric': 'euclidean'}\n",
      "Finish tuning in  0.35 minutes.\n"
     ]
    }
   ],
   "source": [
    "## Tuning of HDBSCAN with outliers\n",
    "results = random_seach_optimization(dm6.X,hdbscan.HDBSCAN,evaluators=evaluators,param_grid=param_grid_full,ascending=ascending, seperating_param_values=True,subsampling=20000, max_evals=450, num_iter=10)\n",
    "#results.to_csv(\"models/cell_dyn_hdbscan_hyper_op_outliers_results_20000.csv\")\n",
    "results_csv_full = pd.read_csv(\"models/cell_dyn_hdbscan_hyper_op_outliers_results_20000.csv\")\n",
    "                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 10% done.\n",
      "Around 20% done.\n",
      "Around 30% done.\n",
      "Around 40% done.\n",
      "Around 50% done.\n",
      "Around 60% done.\n",
      "Around 70% done.\n",
      "Around 80% done.\n",
      "Around 90% done.\n",
      "Around 100% done.\n",
      "Hyperpameter tuning is done and the best scores are:\n",
      "silhouette_score        0.484292\n",
      "davies_bouldin_score    0.593813\n",
      "dunn_fast               0.322062\n",
      "Name: 0, dtype: object\n",
      "Number of unique labels 10\n",
      "with parameter: {'min_samples': 5, 'min_cluster_size': 5, 'cluster_selection_epsilon': 1.0, 'cluster_selection_method': 'leaf', 'metric': 'mahalanobis'}\n",
      "Finish tuning in  729.71 minutes.\n"
     ]
    }
   ],
   "source": [
    "results_subset = grid_seach_optimization(dm6.X,hdbscan.HDBSCAN,evaluators=evaluators,param_grid=param_grid_subset,ascending=ascending, seperating_param_values=True,subsampling=20000, num_iter=10)\n",
    "results_subset.to_csv(\"models/cell_dyn_hdbscan_hyper_op_outliers_results_20000_subset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('CellDynCluster')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5deb914aa631c094dbee2b245fe292bd804ba18ca3cb2d31e687d93fc90e2ee0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
