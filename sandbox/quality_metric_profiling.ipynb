{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the performance of quality metric from hembedder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_cc import *\n",
    "import cProfile\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "\n",
    "sample_index = cell_dyn.sample(40000).index\n",
    "sampled_cd = np.asarray(cell_dyn.loc[sample_index], dtype=np.float32)\n",
    "#sampled_embedded = np.asarray(dm6.loc[sample_index],dtype=np.float16)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Qmatrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing coranking matrix: 100%|██████████| 500/500 [00:00<00:00, 4868.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qmatrix: [[17 10 17 10 12  6  4  6  9  6]\n",
      " [ 7 13  7  8 12  9  7  7  3  6]\n",
      " [17  6  7  7  8  5  7  4  6  6]\n",
      " [ 7  3  4  7  8  5 10  5  9  1]\n",
      " [14 10  5  3  3  3  4  3 11  4]\n",
      " [ 7  6  6  7  9  3  3  3  8  1]\n",
      " [14  4  5  3  8  6  4  4  5  4]\n",
      " [ 4  8  4  3  4  2  4  5  2  8]\n",
      " [ 7  3  7  5  6  7  4  1  3  1]\n",
      " [ 7  6  3  9  7  6  3  6  2  2]]\n",
      "Making scores\n",
      "Qnx: 0.40481042406097334\n",
      "Qtrust: 0.7682598822143694\n",
      "Qcont: 0.801123015312131\n",
      "Qlcmc: 0.3044088176352705\n",
      "QnMRRE: 0.24269459504973911\n",
      "QvMRRE: 0.1930503246904574\n",
      "DistCorr: [0.20843302179522483, 0.08650153185655748, 0.07441534364581859, 0.08521521181977286, 0.23849636418538245]\n",
      "DistCorr level 1: 0.7415913292241197\n",
      "DistCorr level 2: 0.41982542344142426\n",
      "Making Qnx_crm: 0.30440881763527056\n",
      "Making Rnx_crm: 0.22677587317492126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing coranking matrix: 100%|██████████| 500/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Qnx_auc_crm: 0.16568902948141306\n"
     ]
    }
   ],
   "source": [
    "#trustworthiness --> sklearn\n",
    "# distance correlation correlation --> zelf chefffen\n",
    "# knn-overlap - distance curve and integral\n",
    "# poincarre\n",
    "\n",
    "\n",
    "### knn_overlap -> find knn in true space random sample. Then embedding do the same for indices -> jaccard score\n",
    "__author__ = \"Bram van ES\", \"Huibert-Jan Joosse\", \"Chontira Chumsaeng\"\n",
    "\n",
    "from scipy.spatial.distance import jaccard, hamming\n",
    "from scipy.spatial.distance import pdist\n",
    "import scipy as sc\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from sklearn.manifold import trustworthiness\n",
    "import dcor\n",
    "import faiss\n",
    "import time\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import ctypes\n",
    "from ctypes import cdll\n",
    "\n",
    "import hembedder.utils._cpython._metrics_cy as metrics_cy\n",
    "\n",
    "from functools import lru_cache\n",
    "from numba import jit, njit\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import pairwise_distances, pairwise_distances_chunked\n",
    "\n",
    "\"\"\"\n",
    "sources:\n",
    "https://github.com/samueljackson92/coranking/tree/master/src\n",
    "https://github.com/gdkrmr/coRanking/tree/master/R\n",
    "\"\"\"\n",
    "\n",
    "# source : https://timsainburg.com/coranking-matrix-python-numba.html\n",
    "def compute_ranking_matrix_parallel(D):\n",
    "    \"\"\"Compute ranking matrix in parallel. Input (D) is distance matrix\"\"\"\n",
    "    # if data is small, no need for parallel\n",
    "    if len(D) > 1000:\n",
    "        n_jobs = -1\n",
    "    else:\n",
    "        n_jobs = 1\n",
    "    r1 = Parallel(n_jobs, prefer=\"threads\")(\n",
    "        delayed(np.argsort)(i)\n",
    "        for i in tqdm(D.T, desc=\"computing rank matrix\", leave=False)\n",
    "    )\n",
    "    r2 = Parallel(n_jobs, prefer=\"threads\")(\n",
    "        delayed(np.argsort)(i)\n",
    "        for i in tqdm(r1, desc=\"computing rank matrix\", leave=False)\n",
    "    )\n",
    "    # write as a single array\n",
    "    r2_array = np.zeros((len(r2), len(r2[0])), dtype=\"int32\")\n",
    "    for i, r2row in enumerate(tqdm(r2, desc=\"concatenating rank matrix\", leave=False)):\n",
    "        r2_array[i] = r2row\n",
    "    return r2_array\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def populate_Q(Q, i, m, R1, R2):\n",
    "    \"\"\"populate coranking matrix using numba for speed\"\"\"\n",
    "    for j in range(m):\n",
    "        k = R1[i, j]\n",
    "        l = R2[i, j]\n",
    "        Q[k, l] += 1\n",
    "    return Q\n",
    "\n",
    "\n",
    "def iterate_compute_distances(data):\n",
    "    \"\"\"Compute pairwise distance matrix iteratively, so we can see progress\"\"\"\n",
    "    n = len(data)\n",
    "    D = np.zeros((n, n), dtype=\"float32\")\n",
    "    col = 0\n",
    "    for i, distances in enumerate(\n",
    "        pairwise_distances_chunked(data, n_jobs=-1),\n",
    "    ):\n",
    "        D[col : col + len(distances)] = distances\n",
    "    return D\n",
    "\n",
    "\n",
    "def compute_coranking_matrix(data_ld, data_hd=None, D_hd=None, leave = True):\n",
    "    \"\"\"Compute the full coranking matrix\"\"\"\n",
    "\n",
    "    # compute pairwise probabilities\n",
    "    if D_hd is None:\n",
    "        D_hd = iterate_compute_distances(data_hd)\n",
    "\n",
    "    D_ld = iterate_compute_distances(data_ld)\n",
    "    n = len(D_ld)\n",
    "    # compute the ranking matrix for high and low D\n",
    "    rm_hd = compute_ranking_matrix_parallel(D_hd)\n",
    "    rm_ld = compute_ranking_matrix_parallel(D_ld)\n",
    "\n",
    "    # compute coranking matrix from_ranking matrix\n",
    "    m = len(rm_hd)\n",
    "    Q = np.zeros(rm_hd.shape, dtype=\"int16\")\n",
    "    for i in tqdm(range(m), desc=\"computing coranking matrix\", leave = leave):\n",
    "        Q = populate_Q(Q, i, m, rm_hd, rm_ld)\n",
    "\n",
    "    Q = Q[1:, 1:]\n",
    "    return Q\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def qnx_crm(Q: np.array, n_neighbours: int):\n",
    "    \"\"\"Average Normalized Agreement Between K-ary Neighborhoods (QNX)\n",
    "    # QNX measures the degree to which an embedding preserves the local\n",
    "    # neighborhood around each observation. For a value of K, the K closest\n",
    "    # neighbors of each observation are retrieved in the input and output space.\n",
    "    # For each observation, the number of shared neighbors can vary between 0\n",
    "    # and K. QNX is simply the average value of the number of shared neighbors,\n",
    "    # normalized by K, so that if the neighborhoods are perfectly preserved, QNX\n",
    "    # is 1, and if there is no neighborhood preservation, QNX is 0.\n",
    "    #\n",
    "    # For a random embedding, the expected value of QNX is approximately\n",
    "    # K / (N - 1) where N is the number of observations. Using RNX\n",
    "    # (\\code{rnx_crm}) removes this dependency on K and the number of\n",
    "    # observations.\n",
    "    #\n",
    "    # @param crm Co-ranking matrix. Create from a pair of distance matrices with\n",
    "    # \\code{coranking_matrix}.\n",
    "    # @param k Neighborhood size.\n",
    "    # @return QNX for \\code{k}.\n",
    "    # @references\n",
    "    # Lee, J. A., & Verleysen, M. (2009).\n",
    "    # Quality assessment of dimensionality reduction: Rank-based criteria.\n",
    "    # \\emph{Neurocomputing}, \\emph{72(7)}, 1431-1443.\n",
    "\n",
    "    Python reimplmentation of code by jlmelville\n",
    "    (https://github.com/jlmelville/quadra/blob/master/R/neighbor.R)\n",
    "    source: https://timsainburg.com/coranking-matrix-python-numba.html\n",
    "    \"\"\"\n",
    "    qnx_crm_sum = np.sum(Q[:n_neighbours, :n_neighbours])\n",
    "    return qnx_crm_sum / (n_neighbours * len(Q))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def rnx_crm(Q: np.array, n_neighbours: int):\n",
    "    \"\"\"Rescaled Agreement Between K-ary Neighborhoods (RNX)\n",
    "    # RNX is a scaled version of QNX which measures the agreement between two\n",
    "    # embeddings in terms of the shared number of k-nearest neighbors for each\n",
    "    # observation. RNX gives a value of 1 if the neighbors are all preserved\n",
    "    # perfectly and a value of 0 for a random embedding.\n",
    "    #\n",
    "    # @param crm Co-ranking matrix. Create from a pair of distance matrices with\n",
    "    # \\code{coranking_matrix}.\n",
    "    # @param k Neighborhood size.\n",
    "    # @return RNX for \\code{k}.\n",
    "    # @references\n",
    "    # Lee, J. A., Renard, E., Bernard, G., Dupont, P., & Verleysen, M. (2013).\n",
    "    # Type 1 and 2 mixtures of Kullback-Leibler divergences as cost functions in\n",
    "    # dimensionality reduction based on similarity preservation.\n",
    "    # \\emph{Neurocomputing}, \\emph{112}, 92-108.\n",
    "\n",
    "    Python reimplmentation of code by jlmelville\n",
    "    (https://github.com/jlmelville/quadra/blob/master/R/neighbor.R)\n",
    "    source: https://timsainburg.com/coranking-matrix-python-numba.html\n",
    "    \"\"\"\n",
    "    n = len(Q)\n",
    "    return ((qnx_crm(Q, n_neighbours) * (n - 1)) - n_neighbours) / (\n",
    "        n - 1 - n_neighbours\n",
    "    )\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def rnx_auc_crm(Q: np.array):\n",
    "    \"\"\"Area Under the RNX Curve\n",
    "    # The RNX curve is formed by calculating the \\code{rnx_crm} metric for\n",
    "    # different sizes of neighborhood. Each value of RNX is scaled according to\n",
    "    # the natural log of the neighborhood size, to give a higher weight to smaller\n",
    "    # neighborhoods. An AUC of 1 indicates perfect neighborhood preservation, an\n",
    "    # AUC of 0 is due to random results.\n",
    "    #\n",
    "    # param crm Co-ranking matrix.\n",
    "    # return Area under the curve.\n",
    "    # references\n",
    "    # Lee, J. A., Peluffo-Ordo'nez, D. H., & Verleysen, M. (2015).\n",
    "    # Multi-scale similarities in stochastic neighbour embedding: Reducing\n",
    "    # dimensionality while preserving both local and global structure.\n",
    "    # \\emph{Neurocomputing}, \\emph{169}, 246-261.\n",
    "\n",
    "    Python reimplmentation of code by jlmelville\n",
    "    (https://github.com/jlmelville/quadra/blob/master/R/neighbor.R)\n",
    "    source: https://timsainburg.com/coranking-matrix-python-numba.html\n",
    "    \"\"\"\n",
    "    n = len(Q)\n",
    "    num = 0\n",
    "    den = 0\n",
    "\n",
    "    qnx_crm_sum = 0\n",
    "    for k in range(1, n - 2):\n",
    "        # for k in (range(1, n - 2)):\n",
    "        qnx_crm_sum += (\n",
    "            np.sum(Q[(k - 1), :k]) + np.sum(Q[:k, (k - 1)]) - Q[(k - 1), (k - 1)]\n",
    "        )\n",
    "        qnx_crm = qnx_crm_sum / (k * len(Q))\n",
    "        rnx_crm = ((qnx_crm * (n - 1)) - k) / (n - 1 - k)\n",
    "        num += rnx_crm / k\n",
    "        den += 1 / k\n",
    "    return num / den\n",
    "\n",
    "\n",
    "class CDEmbeddingPerformance:\n",
    "    \"\"\"\n",
    "    Class for calulating the embedding quality. Metrics include trustworthiness,\n",
    "    Knn overlap, distance correlation, and random triplet scores\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        metric=\"euclidean\",\n",
    "        n_neighbours: int = 50,\n",
    "        knn_dist: str = \"jaccard\",\n",
    "        dcor_level: int = 2,\n",
    "        num_triplets: int = 5,\n",
    "        dtype=np.float32,\n",
    "        scaled: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Setting up parameters for the quality metircs\n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        metric: string or function\n",
    "            distance metric for trustworiness and distance correlation\n",
    "        n_neighbours:int\n",
    "            number of neighbours for trustworiness and knn overlap scores\n",
    "        knn_dist:string\n",
    "            distance metric for calculating overlap between neighbours in knn overlap.\n",
    "            'hamming' or 'jaccard'\n",
    "        dcor_level:int\n",
    "            depth of correlation; 1 is distance correlation of data, 2 is distance\n",
    "            correlation of distances\n",
    "        num_triplets:int\n",
    "            paramter for random triplets calculation.\n",
    "        dtype: float\n",
    "            for setting type of np.array to work with. If the data set is\n",
    "            too large use np.float16\n",
    "        scaled: bool\n",
    "            whether to use a scaled version of Qnx\n",
    "        \"\"\"\n",
    "        self.metric = metric\n",
    "        self.n_neighbours = n_neighbours\n",
    "        self.knn_dist = knn_dist\n",
    "        self.num_triplets = num_triplets\n",
    "        self.dtype = dtype\n",
    "        self.dcor_level = dcor_level\n",
    "        self.scaled = scaled\n",
    "\n",
    "    def _get_coranking_matrix(self, X_org: np.array, X_emb: np.array, backend=\"numba\"):\n",
    "        \"\"\"\n",
    "        Function for returning the coranking matrix of the original data and the embedded data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        coranking matrix as np.array\n",
    "        \"\"\"\n",
    "\n",
    "        if backend == \"python\":\n",
    "            # source: https://github.com/samueljackson92/coranking/blob/master/coranking/_coranking.py\n",
    "            n, m = X_org.shape\n",
    "            high_distance = sc.spatial.distance.squareform(\n",
    "                sc.spatial.distance.pdist(X_org)\n",
    "            )\n",
    "            low_distance = sc.spatial.distance.squareform(\n",
    "                sc.spatial.distance.pdist(X_emb)\n",
    "            )\n",
    "\n",
    "            high_ranking = high_distance.argsort(axis=1).argsort(axis=1)\n",
    "            low_ranking = low_distance.argsort(axis=1).argsort(axis=1)\n",
    "\n",
    "            Q, xedges, yedges = np.histogram2d(\n",
    "                high_ranking.flatten(), low_ranking.flatten(), bins=n\n",
    "            )\n",
    "            Q = Q.astype(np.int32)\n",
    "            return Q[:1, :1]\n",
    "        elif backend == \"numba\":\n",
    "            Q = compute_coranking_matrix(data_ld=X_emb, data_hd=X_org).astype(np.int32)\n",
    "            return Q\n",
    "        elif backend == \"cython\":\n",
    "            Q = metrics_cy.Qmatrix(X_org, X_emb)\n",
    "            return Q\n",
    "        elif backend == \"ctype\":\n",
    "            script_path = \"/\".join(str(os.path.abspath(__file__)).split(\"/\")[:-1])\n",
    "            coranking = cdll.LoadLibrary(\n",
    "                os.path.join(script_path, \"_ctypes/coranking.so\")\n",
    "            )\n",
    "            # coranking = ctypes.CDLL(os.path.join(script_path, \"_ctypes/coranking.so\"))\n",
    "            # from hembedder.utils._ctypes import coranking\n",
    "\n",
    "            # print(\"Making ravelled arrays\")\n",
    "            # X_org_vector = np.ravel(X_org, order=\"F\")\n",
    "            # X_emb_vector = np.ravel(X_emb, order=\"F\")\n",
    "\n",
    "            print(\"Making C-types variables\")\n",
    "            c_double_C = ctypes.POINTER(ctypes.c_double)\n",
    "            X_org_C = X_org.ctypes.data_as(c_double_C)\n",
    "            X_emb_C = X_emb.ctypes.data_as(c_double_C)\n",
    "\n",
    "            # print(\"Setting up C-types function argument and return types\")\n",
    "            coranking.euclidean.restype = None\n",
    "            coranking.euclidean.argtypes = [\n",
    "                ctypes.POINTER(ctypes.c_double),\n",
    "                ctypes.c_int,\n",
    "                ctypes.c_int,\n",
    "                ctypes.POINTER(ctypes.c_double),\n",
    "            ]\n",
    "\n",
    "            print(\"Calling Ctype function on original data\")\n",
    "            N = X_org.shape[0]\n",
    "            Dor = X_org.shape[1]\n",
    "\n",
    "            DD = np.zeros((N, N), dtype=self.dtype)\n",
    "            DD_ptr = DD.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
    "            coranking.euclidean(X_org_C, N, Dor, DD_ptr)\n",
    "            high_distance = DD.copy()\n",
    "\n",
    "            print(\"Calling Ctype function on embedded data\")\n",
    "            Demb = X_emb.shape[1]\n",
    "\n",
    "            DD = np.zeros((N, N), dtype=self.dtype)\n",
    "            DD_ptr = DD.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
    "            coranking.euclidean(X_emb_C, N, Demb, DD_ptr)\n",
    "            low_distance = DD.copy()\n",
    "\n",
    "            print(\"Calling Ctype function on rankmatrix, original\")\n",
    "            coranking.rankmatrix.restype = None\n",
    "            coranking.rankmatrix.argtypes = [\n",
    "                ctypes.POINTER(ctypes.c_double),\n",
    "                ctypes.c_int,\n",
    "                ctypes.POINTER(ctypes.c_int),\n",
    "            ]\n",
    "\n",
    "            Rm = np.zeros((N, N), dtype=np.int32)\n",
    "            Rm_ptr = Rm.ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
    "            coranking.rankmatrix(\n",
    "                high_distance.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                N,\n",
    "                Rm_ptr,\n",
    "            )\n",
    "            high_ranking = Rm.copy()\n",
    "\n",
    "            print(\"Calling Ctype function on rankmatrix, embedded\")\n",
    "            Rm = np.zeros((N, N), dtype=np.int32)\n",
    "            Rm_ptr = Rm.ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
    "            coranking.rankmatrix(\n",
    "                low_distance.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                N,\n",
    "                Rm_ptr,\n",
    "            )\n",
    "            low_ranking = Rm.copy()\n",
    "\n",
    "            ##\n",
    "            coranking.coranking.restype = None\n",
    "            coranking.coranking.argtypes = [\n",
    "                ctypes.POINTER(ctypes.c_int),\n",
    "                ctypes.POINTER(ctypes.c_int),\n",
    "                ctypes.c_int,\n",
    "                ctypes.POINTER(ctypes.c_int),\n",
    "            ]\n",
    "\n",
    "            print(\"Calling Ctype function on Qmatrix\")\n",
    "            Q = np.zeros((N - 1, N - 1), dtype=np.int32)\n",
    "            Q_ptr = Q.ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
    "            coranking.coranking(\n",
    "                high_ranking.ctypes.data_as(ctypes.POINTER(ctypes.c_int)),\n",
    "                low_ranking.ctypes.data_as(ctypes.POINTER(ctypes.c_int)),\n",
    "                N,\n",
    "                Q_ptr,\n",
    "            )\n",
    "            return Q\n",
    "        else:\n",
    "            raise ValueError(\"Backend not supported\")\n",
    "\n",
    "    def _return_Qnx(self, X_org: np.array, X_emb: np.array, Q: np.array = None):\n",
    "        \"\"\"\n",
    "        Function for returning Qnx score from the original data and the embedded data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        Qnx score as float\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return metrics_cy.Qnx(Q, self.n_neighbours, self.scaled)\n",
    "\n",
    "    def _return_Qtrustworthiness(\n",
    "        self, X_org: np.array, X_emb: np.array, Q: np.array = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Function for returning trustworthiness score from sklearn.manifold.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        Trustworthiness score between 0 and 1. Higher means better\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return metrics_cy.trustworthiness(Q, self.n_neighbours)\n",
    "\n",
    "    def _return_Qcontinuity(self, X_org: np.array, X_emb: np.array, Q: np.array = None):\n",
    "        \"\"\"\n",
    "        Function for returning trustworthiness score from sklearn.manifold.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        Continuity score between 0 and 1. Higher means better\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return metrics_cy.continuity(Q, self.n_neighbours)\n",
    "\n",
    "    def _return_LCMC(self, X_org: np.array, X_emb: np.array, Q: np.array = None):\n",
    "        \"\"\"\n",
    "        Function for returning LCMC score from the original data and the embedded data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        LCMC score as float\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return metrics_cy.LCMC(Q, self.n_neighbours)\n",
    "\n",
    "    def _return_nMRRE(self, X_org: np.array, X_emb: np.array, Q: np.array = None):\n",
    "        \"\"\"\n",
    "        Function for returning LCMC score from the original data and the embedded data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        nMRRE score as float\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return metrics_cy.nMRRE(Q, self.n_neighbours)\n",
    "\n",
    "    def _return_vMRRE(self, X_org: np.array, X_emb: np.array, Q: np.array = None):\n",
    "        \"\"\"\n",
    "        Function for returning LCMC score from the original data and the embedded data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        vMRRE score as float\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return metrics_cy.vMRRE(Q, self.n_neighbours)\n",
    "\n",
    "    def _return_qnx_crm(self, X_org: np.array, X_emb: np.array,Q: np.array=None):\n",
    "        \"\"\"\n",
    "        Function for returning qnx_crm score from the coranking matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        qnx_crm score as float\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return qnx_crm(Q, self.n_neighbours)\n",
    "\n",
    "    def _return_rnx_crm(self, X_org: np.array, X_emb: np.array, Q: np.array=None):\n",
    "        \"\"\"\n",
    "        Function for returning rnx_crm score from the coranking matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "       X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        rnx_crm score as float\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return rnx_crm(Q, self.n_neighbours)\n",
    "\n",
    "    def _return_rnx_auc_crm(self, X_org: np.array, X_emb: np.array, Q: np.array=None):\n",
    "        \"\"\"\n",
    "        Function for returning rnx_auc_crm score from the coranking matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        Q:np.array\n",
    "            the coranking matrix as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        rnx_auc_crm score as float\n",
    "        \"\"\"\n",
    "        if Q is None:\n",
    "            Q = self._get_coranking_matrix(X_org, X_emb)\n",
    "        return rnx_auc_crm(Q)\n",
    "\n",
    "    def _return_trustworthiness(self, X_org: np.array, X_emb: np.array):\n",
    "        \"\"\"\n",
    "        Function for returning trustworthiness score from sklearn.manifold.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        Trustworithiness score between 0 and 1. Higher means better\n",
    "        \"\"\"\n",
    "        return trustworthiness(\n",
    "            X_org, X_emb, n_neighbors=self.n_neighbours, metric=self.metric\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_knn_search(X, k, dtype):\n",
    "        \"\"\"\n",
    "        HELPER function for knn_overlap\n",
    "        \"\"\"\n",
    "        index = faiss.IndexFlatL2(X.shape[1])\n",
    "        index.add(X.astype(dtype))\n",
    "        D, I = index.search(X.astype(dtype), k)\n",
    "        return D, I\n",
    "\n",
    "    def _return_knn_overlap(\n",
    "        self, X_org: np.array, X_emb: np.array, knn_return_median: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Function for returning nearest neighbourhood overlap score.\n",
    "        Overlap between the high dimension and low dimension data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        knn_return_median:bool\n",
    "            whether to return the median of the knn overlap scores.\n",
    "            This should be true if knn is to be used with other methods here.\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        knn overlap score between 0 and 1. Lower means better\n",
    "        \"\"\"\n",
    "        D, I = self._create_knn_search(X_org, self.n_neighbours, self.dtype)\n",
    "        D_emb, I_emb = self._create_knn_search(X_emb, self.n_neighbours, self.dtype)\n",
    "        ds_arry = np.zeros(I.shape[0])\n",
    "        dist = None\n",
    "        if self.knn_dist == \"jaccard\":\n",
    "            dist = jaccard\n",
    "        elif self.knn_dist == \"hamming\":\n",
    "            dist = hamming\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"{self.knn_dist} is not a recognised distance\"\n",
    "                + \" measure for KNN overlap. Please use 'jaccard' or 'hamming'\"\n",
    "            )\n",
    "        for i in range(I.shape[0]):\n",
    "            ds_arry[i] = dist(I[i, :], I_emb[i, :])\n",
    "        return np.median(ds_arry) if knn_return_median else ds_arry\n",
    "\n",
    "    def _return_distance_correlation(self, X_org: np.array, X_emb: np.array):\n",
    "        \"\"\"\n",
    "        Function for returning distance correlation from dcor between the\n",
    "        high dimension and low dimension data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        distance correlation score between 0 and 1. Higher means better\n",
    "        \"\"\"\n",
    "        if self.dcor_level == 1:\n",
    "            return dcor.distance_correlation(X_org, X_emb)\n",
    "        elif self.dcor_level == 2:\n",
    "            return dcor.distance_correlation(\n",
    "                pdist(X_org, metric=\"cityblock\"), pdist(X_emb, metric=\"cityblock\")\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"{self.dcor_level} is not a recognised level for\"\n",
    "                + \" distance correlation. Please use 1 or 2\"\n",
    "            )\n",
    "\n",
    "    def _return_dynamic_distance_correlation(\n",
    "        self, X_org: np.array, X_emb: np.array, n_bins=5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Function for returning dynamic distance correlation from dcor between the\n",
    "        high dimension and low dimension data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        n_bins: int\n",
    "            the number of quantile bins to extract the distance-distance correlation\n",
    "        Returns\n",
    "        -----------\n",
    "        dynamic distance correlation score between 0 and 1. Higher means better\n",
    "        \"\"\"\n",
    "\n",
    "        dist_org = pdist(X_org, metric=\"cityblock\")\n",
    "        dist_emb = pdist(X_emb, metric=\"cityblock\")\n",
    "\n",
    "        d_min = min(dist_org)\n",
    "        d_max = max(dist_org)\n",
    "        d_bins = np.quantile(dist_org, np.linspace(0, 1, n_bins + 1))\n",
    "        d_ranges = list(zip(d_bins[:-1], d_bins[1:]))\n",
    "        res = []\n",
    "        for d_range in d_ranges:\n",
    "            idx = (dist_org >= d_range[0]) & (dist_org <= d_range[1])\n",
    "            res.append(dcor.distance_correlation(dist_emb[idx], dist_org[idx]))\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_distance_random_triplets(X: np.array, anchors, triplets):\n",
    "        \"\"\"\n",
    "        HELPER function for random_triplet_eval to calculate distance\n",
    "        for X and generate the labels\n",
    "        \"\"\"\n",
    "        b = np.broadcast(anchors, triplets)\n",
    "        distances = np.empty(b.shape)\n",
    "        distances.flat = [np.linalg.norm(X[u] - X[v]) for (u, v) in b]\n",
    "        labels = distances[:, :, 0] < distances[:, :, 1]\n",
    "        return labels\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_anchors_and_triplets(X: np.array, num_triplets: int):\n",
    "        \"\"\"\n",
    "        HELPER function for random_triplet_eval to create the\n",
    "        achors and triplets for evaluating thetriplets violation\n",
    "        \"\"\"\n",
    "        anchors = np.arange(X.shape[0])\n",
    "        rng = default_rng()\n",
    "        triplets = rng.choice(anchors, (X.shape[0], num_triplets, 2))\n",
    "        triplet_labels = np.zeros((X.shape[0], num_triplets))\n",
    "        anchors = anchors.reshape((-1, 1, 1))\n",
    "        return anchors, triplets\n",
    "\n",
    "    def random_triplet_eval(self, X_org: np.array, X_emb: np.array):\n",
    "        \"\"\"\n",
    "        Author: Haiyang Huang https://github.com/hyhuang00/scRNA-DR2020/blob/main/experiments/run_eval.py\n",
    "        This is a function that is used to evaluate the lower dimension embedding.\n",
    "        An triplet satisfaction score is calculated by evaluating how many randomly\n",
    "        selected triplets have been violated. Each point will generate 5 triplets.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            X_org: A numpy array with the shape [N, p]. The higher dimension embedding\n",
    "            of some dataset. Expected to have some clusters.\n",
    "            X_emb: A numpy array with the shape [N, k]. The lower dimension embedding\n",
    "                of some dataset. Expected to have some clusters as well.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "            acc: The score generated by the algorithm.\n",
    "        \"\"\"\n",
    "        # Sampling Triplets\n",
    "        # Five triplet per point\n",
    "        anchors, triplets = self.calculate_anchors_and_triplets(\n",
    "            X_org, self.num_triplets\n",
    "        )\n",
    "\n",
    "        # Calculate the distances and generate labels\n",
    "        labels = self.calculate_distance_random_triplets(X_org, anchors, triplets)\n",
    "\n",
    "        # Calculate distances for LD\n",
    "        pred_vals = self.calculate_distance_random_triplets(X_emb, anchors, triplets)\n",
    "\n",
    "        # Compare the labels and return the accuracy\n",
    "        correct = np.sum(pred_vals == labels)\n",
    "        acc = correct / X_org.shape[0] / self.num_triplets\n",
    "        return acc\n",
    "\n",
    "    def neighbor_kept_ratio_eval(self, X_org: np.array, X_emb: np.array):\n",
    "        \"\"\"\n",
    "        Author: Haiyang Huang https://github.com/hyhuang00/scRNA-DR2020/blob/main/experiments/run_eval.py\n",
    "        This is a function that evaluates the local structure preservation.\n",
    "        A nearest neighbor set is constructed on both the high dimensional space and\n",
    "        the low dimensional space.\n",
    "\n",
    "        Input:\n",
    "            X_org: A numpy array with the shape [N, p]. The higher dimension embedding\n",
    "            of some dataset. Expected to have some clusters.\n",
    "            X_emb: A numpy array with the shape [N, k]. The lower dimension embedding\n",
    "                of some dataset. Expected to have some clusters as well.\n",
    "\n",
    "        Output:\n",
    "            acc: The score generated by the algorithm.\n",
    "        \"\"\"\n",
    "        nn_hd = NearestNeighbors(n_neighbors=self.n_neighbours + 1)\n",
    "        nn_ld = NearestNeighbors(n_neighbors=self.n_neighbours + 1)\n",
    "        nn_hd.fit(X_org)\n",
    "        nn_ld.fit(X_emb)\n",
    "        # Construct a k-neighbors graph, where 1 indicates a neighbor relationship\n",
    "        # and 0 means otherwise, resulting in a graph of the shape n * n\n",
    "        graph_hd = nn_hd.kneighbors_graph(X_org).toarray()\n",
    "        graph_hd -= np.eye(X_org.shape[0])  # Removing diagonal\n",
    "        graph_ld = nn_ld.kneighbors_graph(X_emb).toarray()\n",
    "        graph_ld -= np.eye(X_org.shape[0])  # Removing diagonal\n",
    "        neighbor_kept = np.sum(graph_hd * graph_ld).astype(self.dtype)\n",
    "        neighbor_kept_ratio = neighbor_kept / self.n_neighbours / X_org.shape[0]\n",
    "        return neighbor_kept_ratio\n",
    "\n",
    "    def score(\n",
    "        self,\n",
    "        X_org: np.array,\n",
    "        X_emb: np.array,\n",
    "        subsampling: int = 1000,\n",
    "        num_iter: int = 10,\n",
    "        return_results: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Return embedding trustworithness, knn overlap, distance correlation,\n",
    "        and random triplets scores.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_org:np.array\n",
    "            the original dataset as np.array\n",
    "        X_emb:np.array\n",
    "            the embedded data as np.array\n",
    "        subsampling:int\n",
    "            the number of samples for the data to be subsampled down to\n",
    "        num_iter:\n",
    "            the amount of iteration for the algorithms to cycle through\n",
    "            for calculating the scores\n",
    "        return_results:bool\n",
    "            whether to return the results as dictionary\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        final_results:dict, optional\n",
    "            the calculated results in a dictionary.\n",
    "\n",
    "        \"\"\"\n",
    "        evaluators = {\n",
    "            \"Trustworthiness\": self._return_trustworthiness,\n",
    "            \"Knn overlap\": self._return_knn_overlap,\n",
    "            \"Distance correlation\": self._return_distance_correlation,\n",
    "            \"Random triplets\": self.random_triplet_eval,\n",
    "            \"neighbor kept ratio\": self.neighbor_kept_ratio_eval,\n",
    "        }\n",
    "        final_results = score_subsampling(\n",
    "            X_org,\n",
    "            X_emb,\n",
    "            evaluators=evaluators,\n",
    "            size=subsampling,\n",
    "            num_iter=num_iter,\n",
    "            verbose=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        if return_results:\n",
    "            return final_results\n",
    "\n",
    "\n",
    "def metrics_scores_iter(\n",
    "    x: np.array,\n",
    "    output: np.array,\n",
    "    evaluators: dict,\n",
    "    verbose: bool = True,\n",
    "    return_dict: bool = False,\n",
    "    **args\n",
    "):\n",
    "    \"\"\"Calculates scores for embedder using different metrics (evaluators).\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    x: np.array\n",
    "        original unemedded data\n",
    "    output: np.array\n",
    "        output array from the embedder for evaluation\n",
    "    evaluators: dict\n",
    "        further arguments to include the metrics (as function statement in a dict)\n",
    "        if the functions take x and output as arguments.\n",
    "    verbose: bool, optional\n",
    "        whether to print the results.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    results: dict\n",
    "        dictonary of metrics and their calculated scores.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for name, metric in evaluators.items():\n",
    "        results.update({name: metric(x, output,**args)})\n",
    "    if verbose:\n",
    "        print_metric_scores(results)\n",
    "    if return_dict:\n",
    "        return results\n",
    "\n",
    "\n",
    "def print_metric_scores(results: dict):\n",
    "    \"\"\"Print mertic scores in a table format.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    results: dict\n",
    "            dictionary of results to be printed in a table format.\n",
    "    \"\"\"\n",
    "    tab = []\n",
    "    for metric, score in results.items():\n",
    "        tab.append([metric, score])\n",
    "    print(tabulate(tab, headers=[\"Metric\", \"Score\"]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def print_means_metric_scores(results: dict):\n",
    "    \"\"\"Print means of metric scores in a table format with standard deviation.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    results: dict\n",
    "            dictionary of results to be printed in a table format.\n",
    "    \"\"\"\n",
    "    tab = []\n",
    "    for metric, score in results.items():\n",
    "        tab.append([metric, score[0][0], score[0][1]])\n",
    "    print(tabulate(tab, headers=[\"Metric\", \"Mean\", \"Standard deviation\"]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def get_results(args):\n",
    "    \"\"\"HELPER function for parallelisation of this function in score_subsampling\"\"\"\n",
    "    sample = np.random.choice(np.arange(len(args[\"X\"])), size=args[\"size\"])\n",
    "    X_org_sub = args[\"X\"][sample, :]\n",
    "    X_emb_sub = args[\"output\"][sample, :]\n",
    "    results = metrics_scores_iter(\n",
    "        X_org_sub, X_emb_sub, args[\"evaluators\"], verbose=False, return_dict=True\n",
    "    )\n",
    "    for name, score in results.items():\n",
    "        args[\"results\"][name].append(score)\n",
    "    return args[\"results\"]\n",
    "\n",
    "\n",
    "def score_subsampling(\n",
    "    X: np.array,\n",
    "    output: np.array,\n",
    "    evaluators: dict,\n",
    "    size: int = 1000,\n",
    "    num_iter: int = 10,\n",
    "    verbose: bool = True,\n",
    "    return_dict: bool = False,\n",
    "):\n",
    "    \"\"\"Calculates quality metric scores with subsampling to reduce processing time.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    x: np.array\n",
    "        original unemedded data\n",
    "    output: np.array\n",
    "        output array from the embedder for evaluation\n",
    "    evaluators: dict\n",
    "        further arguments to include the metrics (as function statement in a dict)\n",
    "        if the functions take x and output as arguments.\n",
    "    size:int\n",
    "        the number of samples for the data to be subsampled down to\n",
    "    num_iter:\n",
    "        the amount of iteration for the algorithms to cycle through for calculating the scores\n",
    "    verbose: bool, optional\n",
    "        whether to print the results.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    results: dict\n",
    "        dictonary of metrics and their calculated scores.\n",
    "    \"\"\"\n",
    "    results = defaultdict(list)\n",
    "    method_start = time.time()\n",
    "    parallel_param = {\n",
    "        \"X\": X,\n",
    "        \"output\": output,\n",
    "        \"evaluators\": evaluators,\n",
    "        \"size\": size,\n",
    "        \"results\": results,\n",
    "    }\n",
    "    results = Parallel(n_jobs=8, verbose=False, pre_dispatch=\"1.5*n_jobs\")(\n",
    "        delayed(get_results)((parallel_param)) for _ in range(num_iter)\n",
    "    )\n",
    "\n",
    "    results_dict = defaultdict(list)\n",
    "    for i in range(len(results)):\n",
    "        for k, v in results[i].items():\n",
    "            results_dict[k].append(v)\n",
    "\n",
    "    final_results = defaultdict(list)\n",
    "    for name, scores in results_dict.items():\n",
    "        final_results[name].append([np.mean(scores), np.std(scores)])\n",
    "    if verbose:\n",
    "        print_means_metric_scores(final_results)\n",
    "        print(f\"Supsampling of {size} samples for {num_iter} rounds each\")\n",
    "        print(f\"Time taken {round((time.time()-method_start)/60, 2)} minutes\")\n",
    "    if return_dict:\n",
    "        return final_results\n",
    "\n",
    "\n",
    "# add main\n",
    "if __name__ == \"__main__\":\n",
    "    # make synthetic data\n",
    "    from sklearn.datasets import make_regression\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    data_original, _ = make_regression(\n",
    "        n_samples=500, n_features=100, n_informative=10, random_state=42\n",
    "    )\n",
    "    data_embedding = PCA(n_components=10).fit_transform(data_original)\n",
    "\n",
    "    # make evaluator\n",
    "    quality = CDEmbeddingPerformance()\n",
    "\n",
    "    # make Qmatrix\n",
    "    print(\"Making Qmatrix\")\n",
    "    Qmatrix = quality._get_coranking_matrix(\n",
    "        X_org=data_original, X_emb=data_embedding, backend=\"numba\"\n",
    "    )\n",
    "    print(f\"Qmatrix: {Qmatrix[:10, :10]}\")\n",
    "\n",
    "    # make scores\n",
    "    print(\"Making scores\")\n",
    "\n",
    "    Qnx = quality._return_Qnx(X_org=data_original, X_emb=data_embedding, Q=Qmatrix)\n",
    "    print(f\"Qnx: {Qnx}\")\n",
    "\n",
    "    Qtrust = quality._return_Qtrustworthiness(\n",
    "        X_org=data_original, X_emb=data_embedding, Q=Qmatrix\n",
    "    )\n",
    "    print(f\"Qtrust: {Qtrust}\")\n",
    "\n",
    "    Qcont = quality._return_Qcontinuity(\n",
    "        X_org=data_original, X_emb=data_embedding, Q=Qmatrix\n",
    "    )\n",
    "    print(f\"Qcont: {Qcont}\")\n",
    "\n",
    "    Qlcmc = quality._return_LCMC(X_org=data_original, X_emb=data_embedding, Q=Qmatrix)\n",
    "    print(f\"Qlcmc: {Qlcmc}\")\n",
    "\n",
    "    QnMRRE = quality._return_nMRRE(X_org=data_original, X_emb=data_embedding, Q=Qmatrix)\n",
    "    print(f\"QnMRRE: {QnMRRE}\")\n",
    "\n",
    "    QvMRRE = quality._return_vMRRE(X_org=data_original, X_emb=data_embedding, Q=Qmatrix)\n",
    "    print(f\"QvMRRE: {QvMRRE}\")\n",
    "\n",
    "    DistCorr = quality._return_dynamic_distance_correlation(\n",
    "        X_org=data_original, X_emb=data_embedding\n",
    "    )\n",
    "    print(f\"DistCorr: {DistCorr}\")\n",
    "\n",
    "    print(\n",
    "        f\"DistCorr level 1: {dcor.distance_correlation(data_original, data_embedding)}\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"DistCorr level 2: {dcor.distance_correlation(pdist(data_original, metric='cityblock'), pdist(data_embedding, metric='cityblock'))}\"\n",
    "    )\n",
    "\n",
    "    # quality.qnx_crm\n",
    "    print(f\"Making Qnx_crm: {quality._return_qnx_crm(data_original, data_embedding,Qmatrix)}\")\n",
    "    # quality.rnx_crm\n",
    "    print(f\"Making Rnx_crm: {quality._return_rnx_crm(data_original, data_embedding,Qmatrix)}\")\n",
    "    # quality.rnx_auc_crm\n",
    "    print(f\"Making Qnx_auc_crm: {quality._return_rnx_auc_crm(data_original, data_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from hembedder.utils.quality_metrics import compute_coranking_matrix\n",
    "from hembedder.utils import quality_metrics\n",
    "\n",
    "\n",
    "def get_scores(embedded_info): \n",
    "    #Get performance metrics for each subsampled embedder\n",
    "    evaluate_n_n_default = quality_metrics.CDEmbeddingPerformance(dcor_level=2, n_neighbours=15, metric='manhattan')\n",
    "    evaluate = quality_metrics.CDEmbeddingPerformance(dcor_level=1,metric='manhattan')\n",
    "\n",
    "    evaluators = {'Random_triplets' : evaluate.random_triplet_eval,\n",
    "            'dcor_1': evaluate._return_distance_correlation,\n",
    "            'neighbor_kept_50' : evaluate.neighbor_kept_ratio_eval,\n",
    "            'neighbor_kept' : evaluate_n_n_default.neighbor_kept_ratio_eval,\n",
    "            'dcor_2': evaluate_n_n_default._return_distance_correlation,\n",
    "            'Trustworthiness': evaluate._return_trustworthiness,\n",
    "            'LCMC_Q_matrix': evaluate._return_LCMC,\n",
    "            'Trustworthiness_Q_matrix': evaluate._return_Qtrustworthiness,\n",
    "            'Continuit_Q_matrix':  evaluate._return_Qcontinuity,\n",
    "            'nMRRE_Q_matrix' : evaluate._return_nMRRE,\n",
    "            'vMRRE_Q_matrix' : evaluate._return_vMRRE,\n",
    "            'Qnx_crm_Q_matrix': evaluate._return_qnx_crm,\n",
    "            'Rnx_crm_Q_matrix': evaluate._return_rnx_crm,\n",
    "            'Qnx_auc_crm_Q_matrix': evaluate._return_rnx_auc_crm}\n",
    "    embedded_info.update({'evaluators': evaluators})\n",
    "    scores = metrics_scores_iter(**embedded_info)\n",
    "    return scores\n",
    "\n",
    "def get_embedded_data(X,parameter:dict, embedder,num_iter,subsampling):\n",
    "    #Get embedded data from original data by subsampling\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    embedded_data = []\n",
    "    times = []\n",
    "    for iter in range(num_iter):\n",
    "        start = time.time()\n",
    "        sub = numpy_sampling(X, subsampling)\n",
    "        # Evaluate randomly selected hyperparameters\n",
    "        CD_scaled = sub.copy()\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "        CD_scaled = scaler.fit_transform(sub)\n",
    "        # Create a dictionary for later reference in multi-thread\n",
    "        indexes_metrics= subsampling_return_indexes(sub, 5000)\n",
    "        emb_dict = {\"original\" : sub[indexes_metrics],\n",
    "                    \"embedded\" : embedder(**parameter).fit_transform(CD_scaled).astype(np.float32)[indexes_metrics]}\n",
    "        embedded_data.append(emb_dict)\n",
    "        #times.append(time.time()-start)\n",
    "    return embedded_data\n",
    "\n",
    "def get_embedded_without_embedding(X, X_embedded,num_iter,subsampling):\n",
    "    #Get embedded data from original data by subsampling\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    X = np.asarray(X, dtype=np.float16)\n",
    "    X_embedded = np.asarray(X_embedded,dtype=np.float16)\n",
    "    embedded_data = []\n",
    "    for iter in range(num_iter):\n",
    "        sample_index = rng.choice(np.arange(X.shape[0]), size=subsampling, replace=False)\n",
    "        # Create a dictionary for later reference in multi-thread\n",
    "        emb_dict = {\"x\" : X[sample_index],\n",
    "                    \"output\" : X_embedded[sample_index],\n",
    "                    \"Q\":compute_coranking_matrix(X[sample_index],\\\n",
    "                    X_embedded[sample_index], leave = False).astype(np.int32)}\n",
    "        embedded_data.append(emb_dict)\n",
    "        \n",
    "    return embedded_data\n",
    "\n",
    "def metrics_scores_iter(\n",
    "    x: np.array,\n",
    "    output: np.array,\n",
    "    evaluators: dict,\n",
    "    **args\n",
    "):\n",
    "    \"\"\"Calculates scores for embedder using different metrics (evaluators).\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    x: np.array\n",
    "        original unemedded data\n",
    "    output: np.array\n",
    "        output array from the embedder for evaluation\n",
    "    evaluators: dict\n",
    "        further arguments to include the metrics (as function statement in a dict)\n",
    "        if the functions take x and output as arguments.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    results: dict\n",
    "        dictonary of metrics and their calculated scores.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for name, metric in evaluators.items():\n",
    "        if(\"Q\" in args.keys() and \"Q_matrix\" in name):\n",
    "            results.update({name: metric(x, output,args[\"Q\"])})\n",
    "        else:\n",
    "            results.update({name: metric(x, output)})\n",
    "    return results\n",
    "\n",
    "import queue\n",
    "def get_embedded_without_embedding_queue(X, X_embedded,num_iter,subsampling):\n",
    "    #Get embedded data from original data by subsampling\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    X = np.asarray(X, dtype=np.float16)\n",
    "    X_embedded = np.asarray(X_embedded,dtype=np.float16)\n",
    "    embedded_data = queue.Queue()\n",
    "    for iter in range(num_iter):\n",
    "        sample_index = rng.choice(np.arange(X.shape[0]), size=subsampling, replace=False)\n",
    "        print(len(sample_index))\n",
    "        # Create a dictionary for later reference in multi-thread\n",
    "        emb_dict = {\"original\" : X[sample_index],\n",
    "                    \"embedded\" : X_embedded[sample_index]}\n",
    "        embedded_data.put(emb_dict)\n",
    "        \n",
    "    return embedded_data\n",
    "\n",
    "def numpy_sampling(X, subsampling):  \n",
    "    n_data = len(X) \n",
    "    idx = np.arange(n_data) \n",
    "    np.random.shuffle(idx) \n",
    "    return X[idx[: subsampling],:] \n",
    "\n",
    "def subsampling_return_indexes(X, subsampling):\n",
    "    rand = np.random.default_rng()\n",
    "    n_data = len(X) \n",
    "    subsampling = min(n_data, subsampling) \n",
    "    return  rand.choice(np.arange(n_data), size=subsampling, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    }
   ],
   "source": [
    "parameter = {\"n_components\":30}\n",
    "#embedded_data_queue = get_embedded_without_embedding_queue(cell_dyn,dm6,10,10000,evaluators)\n",
    "embedded_data = get_embedded_without_embedding(cell_dyn,dm6,10,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alculating performance for the embedded data using thread pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "pool = ThreadPool(10)\n",
    "scores=pool.map(get_scores, (x for x in embedded_data))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Random_triplets': 0.6980000000000001,\n",
       "  'dcor_1': 0.857933315864784,\n",
       "  'neighbor_kept_50': 0.36995999999999996,\n",
       "  'neighbor_kept': 0.271,\n",
       "  'dcor_2': 0.5484585475678636,\n",
       "  'Trustworthiness': 0.8625359870200109,\n",
       "  'LCMC_Q_matrix': 0.3703303303303303,\n",
       "  'Trustworthiness_Q_matrix': 0.8707269010275819,\n",
       "  'Continuit_Q_matrix': 0.8497877122769066,\n",
       "  'nMRRE_Q_matrix': 0.11064360266384653,\n",
       "  'vMRRE_Q_matrix': 0.13012838020526293,\n",
       "  'Qnx_crm_Q_matrix': 0.3703303303303303,\n",
       "  'Rnx_crm_Q_matrix': 0.33711990471484143,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.26562376230498014},\n",
       " {'Random_triplets': 0.6948000000000001,\n",
       "  'dcor_1': 0.8436501322764045,\n",
       "  'neighbor_kept_50': 0.35975999999999997,\n",
       "  'neighbor_kept': 0.27353333333333335,\n",
       "  'dcor_2': 0.5817533930486691,\n",
       "  'Trustworthiness': 0.8567495294753922,\n",
       "  'LCMC_Q_matrix': 0.3601201201201201,\n",
       "  'Trustworthiness_Q_matrix': 0.860308577609519,\n",
       "  'Continuit_Q_matrix': 0.8400186695511094,\n",
       "  'nMRRE_Q_matrix': 0.12122244162660925,\n",
       "  'vMRRE_Q_matrix': 0.13851077938053308,\n",
       "  'Qnx_crm_Q_matrix': 0.3601201201201201,\n",
       "  'Rnx_crm_Q_matrix': 0.32637118130789017,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.2722555197064202},\n",
       " {'Random_triplets': 0.6964,\n",
       "  'dcor_1': 0.8487096107871657,\n",
       "  'neighbor_kept_50': 0.37306,\n",
       "  'neighbor_kept': 0.27913333333333334,\n",
       "  'dcor_2': 0.5763734587790681,\n",
       "  'Trustworthiness': 0.8540007355327204,\n",
       "  'LCMC_Q_matrix': 0.3734134134134134,\n",
       "  'Trustworthiness_Q_matrix': 0.8684868577609514,\n",
       "  'Continuit_Q_matrix': 0.8415445105462419,\n",
       "  'nMRRE_Q_matrix': 0.11482201199699289,\n",
       "  'vMRRE_Q_matrix': 0.14059801235902794,\n",
       "  'Qnx_crm_Q_matrix': 0.3734134134134134,\n",
       "  'Rnx_crm_Q_matrix': 0.3403655976651757,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.27500662836233297},\n",
       " {'Random_triplets': 0.6958,\n",
       "  'dcor_1': 0.8497289232949113,\n",
       "  'neighbor_kept_50': 0.36184,\n",
       "  'neighbor_kept': 0.26626666666666665,\n",
       "  'dcor_2': 0.5892335845758586,\n",
       "  'Trustworthiness': 0.8552297890751758,\n",
       "  'LCMC_Q_matrix': 0.3622022022022022,\n",
       "  'Trustworthiness_Q_matrix': 0.8649577717685244,\n",
       "  'Continuit_Q_matrix': 0.8408716279069772,\n",
       "  'nMRRE_Q_matrix': 0.11585887136326549,\n",
       "  'vMRRE_Q_matrix': 0.13818732674021136,\n",
       "  'Qnx_crm_Q_matrix': 0.36220220220220223,\n",
       "  'Rnx_crm_Q_matrix': 0.32856307784577826,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.2683444775172447},\n",
       " {'Random_triplets': 0.7,\n",
       "  'dcor_1': 0.8395264381528724,\n",
       "  'neighbor_kept_50': 0.37474,\n",
       "  'neighbor_kept': 0.2648666666666667,\n",
       "  'dcor_2': 0.5670440136362886,\n",
       "  'Trustworthiness': 0.8606206165494862,\n",
       "  'LCMC_Q_matrix': 0.3751151151151151,\n",
       "  'Trustworthiness_Q_matrix': 0.866401384532179,\n",
       "  'Continuit_Q_matrix': 0.8473052244456467,\n",
       "  'nMRRE_Q_matrix': 0.11413781894047119,\n",
       "  'vMRRE_Q_matrix': 0.1356099428418343,\n",
       "  'Qnx_crm_Q_matrix': 0.37511511511511514,\n",
       "  'Rnx_crm_Q_matrix': 0.34215705156633425,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.27186251382104215},\n",
       " {'Random_triplets': 0.704,\n",
       "  'dcor_1': 0.8558424190116544,\n",
       "  'neighbor_kept_50': 0.37939999999999996,\n",
       "  'neighbor_kept': 0.28386666666666666,\n",
       "  'dcor_2': 0.5355607205785013,\n",
       "  'Trustworthiness': 0.8603382152514873,\n",
       "  'LCMC_Q_matrix': 0.3797797797797798,\n",
       "  'Trustworthiness_Q_matrix': 0.8688598161168201,\n",
       "  'Continuit_Q_matrix': 0.8485539643050304,\n",
       "  'nMRRE_Q_matrix': 0.11096266136517116,\n",
       "  'vMRRE_Q_matrix': 0.13075236306178106,\n",
       "  'Qnx_crm_Q_matrix': 0.3797797797797798,\n",
       "  'Rnx_crm_Q_matrix': 0.3470677428483336,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.27626119444994995},\n",
       " {'Random_triplets': 0.708,\n",
       "  'dcor_1': 0.8542789309413286,\n",
       "  'neighbor_kept_50': 0.36992,\n",
       "  'neighbor_kept': 0.2774,\n",
       "  'dcor_2': 0.5745489039969539,\n",
       "  'Trustworthiness': 0.8594407571660357,\n",
       "  'LCMC_Q_matrix': 0.37029029029029026,\n",
       "  'Trustworthiness_Q_matrix': 0.8699013520822056,\n",
       "  'Continuit_Q_matrix': 0.8449525148729039,\n",
       "  'nMRRE_Q_matrix': 0.11297408467932728,\n",
       "  'vMRRE_Q_matrix': 0.13621487841485294,\n",
       "  'Qnx_crm_Q_matrix': 0.3702902902902903,\n",
       "  'Rnx_crm_Q_matrix': 0.33707775285834357,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.27181234262311205},\n",
       " {'Random_triplets': 0.6878,\n",
       "  'dcor_1': 0.8443060623706438,\n",
       "  'neighbor_kept_50': 0.35781999999999997,\n",
       "  'neighbor_kept': 0.2638666666666667,\n",
       "  'dcor_2': 0.5453337784441958,\n",
       "  'Trustworthiness': 0.8515679394267172,\n",
       "  'LCMC_Q_matrix': 0.35817817817817815,\n",
       "  'Trustworthiness_Q_matrix': 0.8578776852352616,\n",
       "  'Continuit_Q_matrix': 0.8358180854515957,\n",
       "  'nMRRE_Q_matrix': 0.12085881685668075,\n",
       "  'vMRRE_Q_matrix': 0.14218911117990007,\n",
       "  'Qnx_crm_Q_matrix': 0.35817817817817815,\n",
       "  'Rnx_crm_Q_matrix': 0.32432681626774457,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.26223004836254543},\n",
       " {'Random_triplets': 0.6852,\n",
       "  'dcor_1': 0.8540039873380444,\n",
       "  'neighbor_kept_50': 0.36910000000000004,\n",
       "  'neighbor_kept': 0.2726,\n",
       "  'dcor_2': 0.5278512429284637,\n",
       "  'Trustworthiness': 0.8509369605191995,\n",
       "  'LCMC_Q_matrix': 0.36946946946946946,\n",
       "  'Trustworthiness_Q_matrix': 0.8663373499188748,\n",
       "  'Continuit_Q_matrix': 0.8376257869118444,\n",
       "  'nMRRE_Q_matrix': 0.11576219621396712,\n",
       "  'vMRRE_Q_matrix': 0.1402639077941303,\n",
       "  'Qnx_crm_Q_matrix': 0.36946946946946946,\n",
       "  'Rnx_crm_Q_matrix': 0.3362136398001377,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.2735907596541445},\n",
       " {'Random_triplets': 0.6982,\n",
       "  'dcor_1': 0.8479722617908338,\n",
       "  'neighbor_kept_50': 0.36454000000000003,\n",
       "  'neighbor_kept': 0.271,\n",
       "  'dcor_2': 0.5428724318767008,\n",
       "  'Trustworthiness': 0.8521384315846403,\n",
       "  'LCMC_Q_matrix': 0.3649049049049049,\n",
       "  'Trustworthiness_Q_matrix': 0.8619674634937801,\n",
       "  'Continuit_Q_matrix': 0.8393384964845862,\n",
       "  'nMRRE_Q_matrix': 0.11797370135749112,\n",
       "  'vMRRE_Q_matrix': 0.13866496156303018,\n",
       "  'Qnx_crm_Q_matrix': 0.3649049049049049,\n",
       "  'Rnx_crm_Q_matrix': 0.33140832815938304,\n",
       "  'Qnx_auc_crm_Q_matrix': 0.26872785202780286}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:822\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    823\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    824\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    825\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    829\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mt:\\laupodteam\\AIOS\\Chontira\\CellDynClustering\\notebook\\quality_metric_profiling.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/t%3A/laupodteam/AIOS/Chontira/CellDynClustering/notebook/quality_metric_profiling.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,pre_dispatch\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m1.5*n_jobs\u001b[39;49m\u001b[39m'\u001b[39;49m)(delayed(get_scores)((embedded_data\u001b[39m.\u001b[39;49mget())) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m10\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:833\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    830\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    831\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 833\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    834\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    835\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;32mt:\\laupodteam\\AIOS\\Chontira\\CellDynClustering\\notebook\\quality_metric_profiling.ipynb Cell 7\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/t%3A/laupodteam/AIOS/Chontira/CellDynClustering/notebook/quality_metric_profiling.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,pre_dispatch\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m1.5*n_jobs\u001b[39m\u001b[39m'\u001b[39m)(delayed(get_scores)((embedded_data\u001b[39m.\u001b[39;49mget())) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=10,verbose=False,pre_dispatch='1.5*n_jobs')(delayed(get_scores)((embedded_data.get())) for _ in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 245790, 1437437, 2533969, 2574939, 1923116, 2057313,  655207,\n",
      "            1434222, 2756490, 2481570],\n",
      "           dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing coranking matrix: 100%|██████████| 1000/1000 [00:00<00:00, 71620.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neigbor kept: 0.35494\n",
      "Random triplet: 0.6906\n",
      "Data correlation: 0.8550623904104924\n",
      "LCMC_Q_matrix 0.3531131131131131\n",
      "Trustworthiness_Q_matrix 0.8380783775013511\n",
      "Continuit_Q_matrix 0.8650885884261764\n",
      "nMRRE_Q_matrix 0.13998568056217425\n",
      "vMRRE_Q_matrix 0.11631446431824963\n",
      "Qnx_crm_Q_matrix 0.3531131131131131\n",
      "Rnx_crm_Q_matrix 0.3189946064207667\n",
      "Qnx_auc_crm_Q_matrix 0.26764033659620323\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#sample_index = cell_dyn.sample(1000).index\n",
    "print(sample_index[0:10])\n",
    "sampled_cd = np.asarray(cell_dyn.loc[sample_index], dtype=np.float32)\n",
    "sampled_emb = np.asarray(dm6.loc[sample_index], dtype=np.float32)\n",
    "evaluate = CDEmbeddingPerformance(knn_dist='jaccard',n_neighbours=50,dcor_level=1,metric='manhattan')\n",
    "Qmatrix = evaluate._get_coranking_matrix(\n",
    "    X_org=data_original, X_emb=data_embedding, backend=\"numba\"\n",
    ")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(sampled_cd,sampled_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(sampled_cd,sampled_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(sampled_cd,sampled_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(sampled_cd,sampled_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(sampled_cd,sampled_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(sampled_cd,sampled_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(sampled_cd,sampled_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(sampled_cd,sampled_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(sampled_cd,sampled_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(sampled_cd,sampled_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(sampled_cd,sampled_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = cell_dyn.sample(40000).index\n",
    "sampled_cd = np.asarray(cell_dyn.loc[sample_index], dtype=np.float32)\n",
    "indexes_metrics= subsampling_return_indexes(sampled_cd, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import trimap\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embedder_6 = umap.UMAP(n_components=6,n_neighbors=15,metric = 'manhattan', output_metric= 'manhattan',\n",
    "                        n_jobs=4, n_epochs=500, init = 'spectral',dens_lambda=0.1, dens_frac=0.1, \n",
    "                        repulsion_strength=1.1, negative_sample_rate=10, random_state=None, min_dist=0.0)\n",
    "\n",
    "embedder_15 = umap.UMAP(n_components=15,n_neighbors=15,metric = 'manhattan', output_metric= 'manhattan',\n",
    "                        n_jobs=4, n_epochs=500, init = 'spectral',dens_lambda=0.1, dens_frac=0.1, \n",
    "                        repulsion_strength=1.1, negative_sample_rate=10, random_state=42, min_dist=0.0)\n",
    "\n",
    "embedder_30 = umap.UMAP(n_components=30,n_neighbors=15,metric = 'manhattan', output_metric= 'manhattan',\n",
    "                        n_jobs=4, n_epochs=500, init = 'spectral',dens_lambda=0.1, dens_frac=0.1, \n",
    "                        repulsion_strength=1.1, negative_sample_rate=10, random_state=42, min_dist=0.0)\n",
    "\n",
    "embedder_60 = umap.UMAP(n_components=60,n_neighbors=15,metric = 'manhattan', output_metric= 'manhattan',\n",
    "                        n_jobs=4, n_epochs=500, init = 'spectral',dens_lambda=0.1, dens_frac=0.1, \n",
    "                        repulsion_strength=1.1, negative_sample_rate=10, random_state=42, min_dist=0.0)\n",
    "\n",
    "trimap_model_6 = trimap.TRIMAP(n_dims=6,n_inliers=100)\n",
    "trimap_model_15 = trimap.TRIMAP(n_dims=15,n_inliers=100)\n",
    "trimap_model_30 = trimap.TRIMAP(n_dims=30,n_inliers=100)\n",
    "trimap_model_60 = trimap.TRIMAP(n_dims=60,n_inliers=100)\n",
    "\n",
    "\n",
    "pca_model_6 = PCA(n_components=6,whiten=False)\n",
    "pca_model_15 = PCA(n_components=15,whiten=False)\n",
    "pca_model_30 = PCA(n_components=30,whiten=False)\n",
    "pca_model_60 = PCA(n_components=60,whiten=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('embedder',\n",
      "                 UMAP(dens_frac=0.1, dens_lambda=0.1, metric='manhattan', min_dist=0.0, n_components=6, n_epochs=500, n_jobs=4, negative_sample_rate=10, output_metric='manhattan', repulsion_strength=1.1, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]', 'desc': 'Epochs completed', 'disable': True}))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:6\n",
      "Neigbor kept: 0.31895999999999997\n",
      "Random triplet: 0.7316\n",
      "Data correlation: 0.8314121390611661\n",
      "LCMC_Q_matrix 0.3192792792792793\n",
      "Trustworthiness_Q_matrix 0.8326470740941063\n",
      "Continuit_Q_matrix 0.8740711736073558\n",
      "nMRRE_Q_matrix 0.14994091839251278\n",
      "vMRRE_Q_matrix 0.11232715034163432\n",
      "Qnx_crm_Q_matrix 0.3192792792792793\n",
      "Rnx_crm_Q_matrix 0.28337628768008516\n",
      "Qnx_auc_crm_Q_matrix 0.26580794088317417\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import resample\n",
    "le_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('embedder', embedder_6)])\n",
    "\n",
    "le_pipe.fit(sampled_cd)\n",
    "evaluate = CDEmbeddingPerformance(knn_dist='jaccard',n_neighbours=50,dcor_level=1,metric='manhattan')\n",
    "eval_sample = sampled_cd[indexes_metrics].astype(np.float32)\n",
    "eval_emb = le_pipe.named_steps['embedder'].embedding_[indexes_metrics].astype(np.float32)\n",
    "print(le_pipe)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('embedder',\n",
      "                 UMAP(dens_frac=0.1, dens_lambda=0.1, metric='manhattan', min_dist=0.0, n_components=15, n_epochs=500, n_jobs=4, negative_sample_rate=10, output_metric='manhattan', random_state=42, repulsion_strength=1.1, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]', 'desc': 'Epochs completed', 'disable': True}))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:15\n",
      "Neigbor kept: 0.21653333333333333\n",
      "Random triplet: 0.7422\n",
      "Data correlation: 0.837293519493167\n",
      "LCMC_Q_matrix 0.2167500834167501\n",
      "Trustworthiness_Q_matrix 0.8611037871033774\n",
      "Continuit_Q_matrix 0.8992487205731831\n",
      "nMRRE_Q_matrix 0.1304529010282032\n",
      "vMRRE_Q_matrix 0.09659567956241343\n",
      "Qnx_crm_Q_matrix 0.2167500834167501\n",
      "Rnx_crm_Q_matrix 0.20479815183104436\n",
      "Qnx_auc_crm_Q_matrix 0.26176613400052695\n"
     ]
    }
   ],
   "source": [
    "le_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('embedder', embedder_15)])\n",
    "\n",
    "le_pipe.fit(sampled_cd)\n",
    "evaluate = CDEmbeddingPerformance(knn_dist='jaccard',n_neighbours=15,dcor_level=1,metric='manhattan')\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = le_pipe.named_steps['embedder'].embedding_[indexes_metrics]\n",
    "print(le_pipe)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('embedder',\n",
      "                 UMAP(dens_frac=0.1, dens_lambda=0.1, metric='manhattan', min_dist=0.0, n_components=30, n_epochs=500, n_jobs=4, negative_sample_rate=10, output_metric='manhattan', random_state=42, repulsion_strength=1.1, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]', 'desc': 'Epochs completed', 'disable': True}))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:30\n",
      "Neigbor kept: 0.21293333333333334\n",
      "Random triplet: 0.7478\n",
      "Data correlation: 0.8416469400952796\n",
      "LCMC_Q_matrix 0.2131464798131465\n",
      "Trustworthiness_Q_matrix 0.8558676902081201\n",
      "Continuit_Q_matrix 0.8976244285226884\n",
      "nMRRE_Q_matrix 0.13892264410215557\n",
      "vMRRE_Q_matrix 0.09812893951338567\n",
      "Qnx_crm_Q_matrix 0.21314647981314647\n",
      "Rnx_crm_Q_matrix 0.20113955936268582\n",
      "Qnx_auc_crm_Q_matrix 0.2574650013857491\n"
     ]
    }
   ],
   "source": [
    "le_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('embedder', embedder_30)])\n",
    "\n",
    "le_pipe.fit(sampled_cd)\n",
    "evaluate = CDEmbeddingPerformance(knn_dist='jaccard',n_neighbours=15,dcor_level=1,metric='manhattan')\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = le_pipe.named_steps['embedder'].embedding_[indexes_metrics]\n",
    "print(le_pipe)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('embedder',\n",
      "                 UMAP(dens_frac=0.1, dens_lambda=0.1, metric='manhattan', min_dist=0.0, n_components=60, n_epochs=500, n_jobs=4, negative_sample_rate=10, output_metric='manhattan', random_state=42, repulsion_strength=1.1, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]', 'desc': 'Epochs completed', 'disable': True}))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:60\n",
      "Neigbor kept: 0.20633333333333334\n",
      "Random triplet: 0.7482\n",
      "Data correlation: 0.8400091763938826\n",
      "LCMC_Q_matrix 0.20653987320653988\n",
      "Trustworthiness_Q_matrix 0.8500644148754687\n",
      "Continuit_Q_matrix 0.894979324462641\n",
      "nMRRE_Q_matrix 0.14667538268975117\n",
      "vMRRE_Q_matrix 0.10104495947409989\n",
      "Qnx_crm_Q_matrix 0.20653987320653988\n",
      "Rnx_crm_Q_matrix 0.19443213983736196\n",
      "Qnx_auc_crm_Q_matrix 0.2490579763099267\n"
     ]
    }
   ],
   "source": [
    "le_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('embedder', embedder_60)])\n",
    "le_pipe.fit(sampled_cd)\n",
    "evaluate = CDEmbeddingPerformance(knn_dist='jaccard',n_neighbours=15,dcor_level=1,metric='manhattan')\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = le_pipe.named_steps['embedder'].embedding_[indexes_metrics]\n",
    "print(le_pipe)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIMAP(n_dims=6, n_inliers=100,\n",
      "       triplets=array([[    0, 15424,  3228],\n",
      "       [    0, 15424, 21376],\n",
      "       [    0, 15424,  6681],\n",
      "       ...,\n",
      "       [39999, 32039, 10343],\n",
      "       [39999, 39772, 17810],\n",
      "       [39999, 28809,  7514]]),\n",
      "       weights=array([6.8382864, 6.5751486, 7.491781 , ..., 6.294773 , 6.2631865,\n",
      "       6.334531 ], dtype=float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:6\n",
      "Neigbor kept: 0.3280666666666667\n",
      "Random triplet: 0.8068\n",
      "Data correlation: 0.9025855110710718\n",
      "LCMC_Q_matrix 0.32839506172839505\n",
      "Trustworthiness_Q_matrix 0.9269045377004437\n",
      "Continuit_Q_matrix 0.9419904469464346\n",
      "nMRRE_Q_matrix 0.06863076261549153\n",
      "vMRRE_Q_matrix 0.05383520007681549\n",
      "Qnx_crm_Q_matrix 0.32839506172839505\n",
      "Rnx_crm_Q_matrix 0.3181467666377806\n",
      "Qnx_auc_crm_Q_matrix 0.36014600630198357\n"
     ]
    }
   ],
   "source": [
    "scaled = StandardScaler().fit_transform(sampled_cd)\n",
    "embedded = trimap_model_6.fit_transform(scaled)\n",
    "\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = embedded[indexes_metrics]\n",
    "print(trimap_model_6)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIMAP(n_dims=15, n_inliers=100,\n",
      "       triplets=array([[    0, 15424, 19766],\n",
      "       [    0, 15424, 17953],\n",
      "       [    0, 15424,  9526],\n",
      "       ...,\n",
      "       [39999,   301, 12924],\n",
      "       [39999,  7374,  4620],\n",
      "       [39999, 27268, 14299]]),\n",
      "       weights=array([7.3979683, 8.351147 , 7.492214 , ..., 6.6569643, 6.6721582,\n",
      "       6.783514 ], dtype=float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:15\n",
      "Neigbor kept: 0.3283333333333333\n",
      "Random triplet: 0.7976\n",
      "Data correlation: 0.9023530926910625\n",
      "LCMC_Q_matrix 0.328661995328662\n",
      "Trustworthiness_Q_matrix 0.9268503582395088\n",
      "Continuit_Q_matrix 0.9422067553735926\n",
      "nMRRE_Q_matrix 0.06917706096215273\n",
      "vMRRE_Q_matrix 0.053691940044720506\n",
      "Qnx_crm_Q_matrix 0.32866199532866197\n",
      "Rnx_crm_Q_matrix 0.3184177734872886\n",
      "Qnx_auc_crm_Q_matrix 0.3576956214139882\n"
     ]
    }
   ],
   "source": [
    "scaled = StandardScaler().fit_transform(sampled_cd)\n",
    "embedded = trimap_model_15.fit_transform(scaled)\n",
    "\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = embedded[indexes_metrics]\n",
    "print(trimap_model_15)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIMAP(n_dims=30, n_inliers=100,\n",
      "       triplets=array([[    0, 15424, 15319],\n",
      "       [    0, 15424,  2089],\n",
      "       [    0, 15424, 30134],\n",
      "       ...,\n",
      "       [39999, 16866,  3980],\n",
      "       [39999, 23163,  9417],\n",
      "       [39999, 28677,  6399]]),\n",
      "       weights=array([7.1482916, 7.5403175, 7.840534 , ..., 6.0202646, 6.2372847,\n",
      "       6.06056  ], dtype=float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:30\n",
      "Neigbor kept: 0.32426666666666665\n",
      "Random triplet: 0.8008\n",
      "Data correlation: 0.9020093814631172\n",
      "LCMC_Q_matrix 0.32459125792459126\n",
      "Trustworthiness_Q_matrix 0.9261061753667692\n",
      "Continuit_Q_matrix 0.9418535653360628\n",
      "nMRRE_Q_matrix 0.07046743587174875\n",
      "vMRRE_Q_matrix 0.05397987417911751\n",
      "Qnx_crm_Q_matrix 0.32459125792459126\n",
      "Rnx_crm_Q_matrix 0.31428491903229105\n",
      "Qnx_auc_crm_Q_matrix 0.357072148638206\n"
     ]
    }
   ],
   "source": [
    "scaled = StandardScaler().fit_transform(sampled_cd)\n",
    "embedded = trimap_model_30.fit_transform(scaled)\n",
    "\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = embedded[indexes_metrics]\n",
    "print(trimap_model_30)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIMAP(n_dims=60, n_inliers=100,\n",
      "       triplets=array([[    0, 15424, 13851],\n",
      "       [    0, 15424, 22303],\n",
      "       [    0, 15424, 17084],\n",
      "       ...,\n",
      "       [39999, 20240, 23637],\n",
      "       [39999, 35311,  1902],\n",
      "       [39999, 27358,   153]]),\n",
      "       weights=array([6.918337 , 6.8965816, 7.0562963, ..., 5.9520035, 5.947644 ,\n",
      "       5.9446588], dtype=float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:60\n",
      "Neigbor kept: 0.32913333333333333\n",
      "Random triplet: 0.7964\n",
      "Data correlation: 0.9018334511685676\n",
      "LCMC_Q_matrix 0.32946279612946283\n",
      "Trustworthiness_Q_matrix 0.9263605595359947\n",
      "Continuit_Q_matrix 0.941856021835551\n",
      "nMRRE_Q_matrix 0.06961428244691169\n",
      "vMRRE_Q_matrix 0.053983500154032554\n",
      "Qnx_crm_Q_matrix 0.3294627961294628\n",
      "Rnx_crm_Q_matrix 0.31923079403581267\n",
      "Qnx_auc_crm_Q_matrix 0.3575831041152795\n"
     ]
    }
   ],
   "source": [
    "scaled = StandardScaler().fit_transform(sampled_cd)\n",
    "embedded = trimap_model_60.fit_transform(scaled)\n",
    "\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = embedded[indexes_metrics]\n",
    "print(trimap_model_60)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(n_components=6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:6\n",
      "Neigbor kept: 0.38339999999999996\n",
      "Random triplet: 0.8762000000000001\n",
      "Data correlation: 0.9703182949450857\n",
      "LCMC_Q_matrix 0.3837837837837838\n",
      "Trustworthiness_Q_matrix 0.9377617877857386\n",
      "Continuit_Q_matrix 0.9748347321733197\n",
      "nMRRE_Q_matrix 0.06385704992885587\n",
      "vMRRE_Q_matrix 0.025297625566066094\n",
      "Qnx_crm_Q_matrix 0.3837837837837838\n",
      "Rnx_crm_Q_matrix 0.37438068791069806\n",
      "Qnx_auc_crm_Q_matrix 0.44376689332919744\n"
     ]
    }
   ],
   "source": [
    "scaled = StandardScaler().fit_transform(sampled_cd)\n",
    "embedded = pca_model_6.fit_transform(scaled)\n",
    "\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = embedded[indexes_metrics]\n",
    "print(pca_model_6)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(n_components=15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:15\n",
      "Neigbor kept: 0.6606666666666666\n",
      "Random triplet: 0.9410000000000001\n",
      "Data correlation: 0.9929370326063357\n",
      "LCMC_Q_matrix 0.6613279946613281\n",
      "Trustworthiness_Q_matrix 0.9899703172978506\n",
      "Continuit_Q_matrix 0.9952517911975435\n",
      "nMRRE_Q_matrix 0.01117437946748195\n",
      "vMRRE_Q_matrix 0.006406037268180344\n",
      "Qnx_crm_Q_matrix 0.661327994661328\n",
      "Rnx_crm_Q_matrix 0.6561600596866789\n",
      "Qnx_auc_crm_Q_matrix 0.6775205455262224\n"
     ]
    }
   ],
   "source": [
    "scaled = StandardScaler().fit_transform(sampled_cd)\n",
    "embedded = pca_model_15.fit_transform(scaled)\n",
    "\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = embedded[indexes_metrics]\n",
    "print(pca_model_15)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(n_components=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:30\n",
      "Neigbor kept: 0.8323333333333334\n",
      "Random triplet: 0.976\n",
      "Data correlation: 0.9984531319129384\n",
      "LCMC_Q_matrix 0.8331664998331665\n",
      "Trustworthiness_Q_matrix 0.9982116001364721\n",
      "Continuit_Q_matrix 0.9990639372227909\n",
      "nMRRE_Q_matrix 0.0030769554507460144\n",
      "vMRRE_Q_matrix 0.002222257699399505\n",
      "Qnx_crm_Q_matrix 0.8331664998331665\n",
      "Rnx_crm_Q_matrix 0.8306207190574774\n",
      "Qnx_auc_crm_Q_matrix 0.8392600051468195\n"
     ]
    }
   ],
   "source": [
    "scaled = StandardScaler().fit_transform(sampled_cd)\n",
    "embedded = pca_model_30.fit_transform(scaled)\n",
    "\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = embedded[indexes_metrics]\n",
    "print(pca_model_30)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(n_components=60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component number:60\n",
      "Neigbor kept: 0.9806666666666666\n",
      "Random triplet: 0.9970000000000001\n",
      "Data correlation: 0.9999504426390688\n",
      "LCMC_Q_matrix 0.9816483149816484\n",
      "Trustworthiness_Q_matrix 0.9999701125895599\n",
      "Continuit_Q_matrix 0.9999701125895599\n",
      "nMRRE_Q_matrix 0.00022338573497048252\n",
      "vMRRE_Q_matrix 0.00022166357017603733\n",
      "Qnx_crm_Q_matrix 0.9816483149816483\n",
      "Rnx_crm_Q_matrix 0.9813682790963225\n",
      "Qnx_auc_crm_Q_matrix 0.9842869560561471\n"
     ]
    }
   ],
   "source": [
    "scaled = StandardScaler().fit_transform(sampled_cd)\n",
    "embedded = pca_model_60.fit_transform(scaled)\n",
    "\n",
    "eval_sample = sampled_cd[indexes_metrics]\n",
    "eval_emb = embedded[indexes_metrics]\n",
    "print(pca_model_60)\n",
    "Qmatrix = quality._get_coranking_matrix(\n",
    "    X_org=eval_sample, X_emb=eval_emb, backend=\"numba\"\n",
    ")\n",
    "print(f\"component number:{eval_emb.shape[1]}\")\n",
    "print(\"Neigbor kept:\",evaluate.neighbor_kept_ratio_eval(eval_sample,eval_emb))\n",
    "print(\"Random triplet:\",evaluate.random_triplet_eval(eval_sample,eval_emb))\n",
    "print(\"Data correlation:\",evaluate._return_distance_correlation(eval_sample,eval_emb))\n",
    "print('LCMC_Q_matrix', evaluate._return_LCMC(eval_sample,eval_emb,Qmatrix))\n",
    "print('Trustworthiness_Q_matrix', evaluate._return_Qtrustworthiness(eval_sample,eval_emb,Qmatrix))\n",
    "print('Continuit_Q_matrix',  evaluate._return_Qcontinuity(eval_sample,eval_emb,Qmatrix))\n",
    "print('nMRRE_Q_matrix' , evaluate._return_nMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('vMRRE_Q_matrix' , evaluate._return_vMRRE(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_crm_Q_matrix', evaluate._return_qnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Rnx_crm_Q_matrix', evaluate._return_rnx_crm(eval_sample,eval_emb,Qmatrix))\n",
    "print('Qnx_auc_crm_Q_matrix', evaluate._return_rnx_auc_crm(eval_sample,eval_emb,Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1443 function calls in 217.289 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        4    0.000    0.000  217.288   54.322 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3362(run_code)\n",
      "        4    0.000    0.000  217.288   54.322 {built-in method builtins.exec}\n",
      "        1    0.000    0.000  217.288  217.288 C:\\Users\\cchumsae\\AppData\\Local\\Temp\\ipykernel_20596\\3697458949.py:1(<cell line: 11>)\n",
      "        1    0.000    0.000  217.288  217.288 C:\\Users\\cchumsae\\AppData\\Local\\Temp\\ipykernel_20596\\865909864.py:295(score_subsampling)\n",
      "        1    0.000    0.000  217.288  217.288 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:960(__call__)\n",
      "        1    0.000    0.000  217.175  217.175 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:920(retrieve)\n",
      "       10    0.000    0.000  217.175   21.717 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:537(wrap_future_result)\n",
      "       10    0.000    0.000  217.175   21.717 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\concurrent\\futures\\_base.py:418(result)\n",
      "        7    0.000    0.000  217.175   31.025 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\threading.py:288(wait)\n",
      "       35  217.174    6.205  217.174    6.205 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.110    0.110 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:757(_terminate_backend)\n",
      "        1    0.000    0.000    0.110    0.110 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:546(terminate)\n",
      "        1    0.000    0.000    0.109    0.109 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:612(_unlink_temporary_resources)\n",
      "        1    0.000    0.000    0.109    0.109 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:644(_try_delete_folder)\n",
      "        1    0.000    0.000    0.109    0.109 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\disk.py:105(delete_folder)\n",
      "        1    0.107    0.107    0.107    0.107 {built-in method time.sleep}\n",
      "        1    0.000    0.000    0.002    0.002 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:732(_initialize_backend)\n",
      "        1    0.000    0.000    0.002    0.002 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:486(configure)\n",
      "        5    0.002    0.000    0.002    0.000 {built-in method nt.stat}\n",
      "        4    0.000    0.000    0.002    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\genericpath.py:16(exists)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\executor.py:19(get_memmapping_executor)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\executor.py:25(get_memmapping_executor)\n",
      "        8    0.000    0.000    0.001    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:798(dispatch_one_batch)\n",
      "        2    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:537(register_new_context)\n",
      "        2    0.000    0.000    0.001    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:168(_get_temp_dir)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:154(_prepare_worker_env)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110(cpu_count)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:169(_cpu_count_user)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\shutil.py:685(rmtree)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:518(__init__)\n",
      "        7    0.000    0.000    0.001    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:761(_dispatch)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:533(set_current_context)\n",
      "        3    0.001    0.000    0.001    0.000 {built-in method nt.listdir}\n",
      "        7    0.000    0.000    0.001    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:529(apply_async)\n",
      "        7    0.000    0.000    0.001    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:175(submit)\n",
      "        7    0.000    0.000    0.001    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1112(submit)\n",
      "        1    0.000    0.000    0.001    0.001 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\shutil.py:593(_rmtree_unsafe)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:138(wakeup)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\connection.py:186(send_bytes)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\connection.py:284(_send_bytes)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt.rmdir}\n",
      "        4    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\codeop.py:117(__call__)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'GetOverlappedResult' of '_winapi.Overlapped' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\shutil.py:574(_rmtree_islink)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:567(_unregister_context)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt.lstat}\n",
      "        4    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:94(ensure_running)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:203(_send)\n",
      "        4    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:179(_check_alive)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\genericpath.py:39(isdir)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:639(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt.scandir}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:193(unregister)\n",
      "       14    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\queue.py:122(put)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:198(maybe_unlink)\n",
      "        3    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\ntpath.py:77(join)\n",
      "        7    0.000    0.000    0.000    0.000 C:\\Users\\cchumsae\\AppData\\Local\\Temp\\ipykernel_20596\\865909864.py:326(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:583(register_folder_finalizer)\n",
      "       10    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\queue.py:154(get)\n",
      "        4    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3215(_update_code_co_name)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:321(delayed)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method nt.write}\n",
      "        3    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\uuid.py:713(uuid4)\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:188(register)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\concurrent\\futures\\_base.py:318(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\contextlib.py:139(__exit__)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1104(_ensure_executor_running)\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\ntpath.py:537(abspath)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\ntpath.py:124(splitdrive)\n",
      "       10    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\threading.py:236(__init__)\n",
      "       13    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.eval}\n",
      "       10    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\_collections_abc.py:816(get)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\functools.py:35(update_wrapper)\n",
      "      135    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       41    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\threading.py:264(__enter__)\n",
      "       21    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\threading.py:359(notify)\n",
      "       41    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\threading.py:267(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\ntpath.py:463(normpath)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\contextlib.py:279(helper)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\logger.py:39(short_format_time)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _winapi.WriteFile}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method atexit.unregister}\n",
      "        4    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\traitlets\\traitlets.py:566(__get__)\n",
      "       11    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\os.py:674(__getitem__)\n",
      "        3    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\uuid.py:138(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\concurrent\\futures\\_base.py:398(add_done_callback)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\contextlib.py:102(__init__)\n",
      "       80    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        4    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\traitlets\\traitlets.py:535(get)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\queue.py:34(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 {method '_acquire_restore' of '_thread.RLock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:124(get_nested_backend)\n",
      "        5    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\contextlib.py:130(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:105(get_reusable_executor)\n",
      "       11    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\os.py:746(encodekey)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\logger.py:23(_squeeze_time)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:76(get_active_backend)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\threading.py:90(RLock)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\dis.py:453(findlinestarts)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:501(effective_n_jobs)\n",
      "       21    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\threading.py:279(_is_owned)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\cchumsae\\AppData\\Local\\Temp\\ipykernel_20596\\3697458949.py:1(<cell line: 12>)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:245(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\tempfile.py:297(gettempdir)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\IPython\\core\\compilerop.py:174(extra_flags)\n",
      "       10    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\concurrent\\futures\\_base.py:388(__get_result)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:473(get_memmapping_reducers)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:34(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method nt.urandom}\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\synchronize.py:94(__enter__)\n",
      "       51    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       14    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\queue.py:213(_put)\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       42    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\ntpath.py:289(expanduser)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3313(compare)\n",
      "        8    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:285(compute_batch_size)\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\os.py:816(fsdecode)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\synchronize.py:97(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'replace' of 'code' objects}\n",
      "       10    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\queue.py:209(_qsize)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:280(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\disk.py:42(memstr_to_bytes)\n",
      "       17    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.RLock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "       35    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\context.py:41(cpu_count)\n",
      "        7    0.000    0.000    0.000    0.000 {method '_release_save' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:338(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\os.py:740(check_str)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\queue.py:217(_get)\n",
      "       21    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\functools.py:65(wraps)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:260(__init__)\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method nt.fspath}\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:345(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:185(in_main_thread)\n",
      "       35    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        4    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\IPython\\core\\interactiveshell.py:1192(user_global_ns)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\cchumsae\\AppData\\Local\\Temp\\ipykernel_20596\\3697458949.py:1(<cell line: 5>)\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\util.py:48(debug)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt._getfullpathname}\n",
      "        3    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\uuid.py:333(hex)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "       24    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt.cpu_count}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:361(reset_batch_stats)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:180(_resize)\n",
      "       21    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:275(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\process.py:198(daemon)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1047(_start_executor_manager_thread)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\pickle.py:335(whichmodule)\n",
      "        7    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\cchumsae\\AppData\\Local\\Temp\\ipykernel_20596\\3697458949.py:1(<cell line: 6>)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\_collections_abc.py:823(__contains__)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\connection.py:139(_check_closed)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:590(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\threading.py:1423(current_thread)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:864(_print)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\connection.py:147(_check_writable)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'nt.ScandirIterator' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method '_is_owned' of '_thread.RLock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'co_lines' of 'code' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\cchumsae\\AppData\\Local\\Temp\\ipykernel_20596\\865909864.py:19(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\tempfile.py:285(_gettempdir)\n",
      "        7    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\parallel.py:324(delayed_function)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\queue.py:206(_init)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\context.py:233(get_context)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method sys.audit}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\multiprocessing\\process.py:37(current_process)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:137(retrieval_context)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_memmapping_reducer.py:115(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:83(stop_call)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\cchumsae\\Anaconda3\\envs\\CellDynCluster\\lib\\site-packages\\joblib\\_parallel_backends.py:80(start_call)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "evaluate = CDEmbeddingPerformance(knn_dist='jaccard',n_neighbours=15)\n",
    "evaluators = {'Trustworthiness': evaluate._return_trustworthiness,\n",
    "                    'Knn overlap': evaluate._return_knn_overlap,\n",
    "                    'Distance correlation': evaluate._return_distance_correlation,\n",
    "                    'Random triplets' : evaluate.random_triplet_eval,\n",
    "                    'neighbor kept ratio' : evaluate.neighbor_kept_ratio_eval}\n",
    "final_results=score_subsampling(sampled_cd,sampled_embedded,evaluators,size=20000)\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "sortby = SortKey.CUMULATIVE\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats()\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         704 function calls (685 primitive calls) in 34.516 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(all)\n",
      "        1    0.000    0.000   25.814   25.814 <__array_function__ internals>:2(argsort)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(atleast_2d)\n",
      "        1    0.000    0.000    0.001    0.001 <__array_function__ internals>:2(concatenate)\n",
      "        1    0.000    0.000    0.001    0.001 <__array_function__ internals>:2(copyto)\n",
      "        1    0.000    0.000    0.002    0.002 <__array_function__ internals>:2(einsum)\n",
      "        2    0.000    0.000    0.002    0.001 <__array_function__ internals>:2(fill_diagonal)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(reshape)\n",
      "        5    0.000    0.000    0.004    0.001 <__array_function__ internals>:2(sum)\n",
      "        1    0.000    0.000    0.001    0.001 <__array_function__ internals>:2(vstack)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:404(parent)\n",
      "        1    0.000    0.000   34.516   34.516 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:748(gen_even_slices)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:335(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:357(_check_algorithm_metric)\n",
      "        1    0.025    0.025    0.026    0.026 _base.py:404(_fit)\n",
      "        2    0.000    0.000    0.000    0.000 _base.py:612(_more_tags)\n",
      "        1    0.000    0.000    0.611    0.611 _base.py:617(_tree_query_parallel_helper)\n",
      "        1    0.003    0.003    0.617    0.617 _base.py:670(kneighbors)\n",
      "        2    0.000    0.000    0.000    0.000 _base.py:814(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 _config.py:133(config_context)\n",
      "        8    0.000    0.000    0.000    0.000 _config.py:20(_get_threadlocal_config)\n",
      "        6    0.000    0.000    0.000    0.000 _config.py:28(get_config)\n",
      "        2    0.000    0.000    0.000    0.000 _config.py:46(set_config)\n",
      "        2    0.000    0.000    0.000    0.000 _parallel_backends.py:137(retrieval_context)\n",
      "        2    0.000    0.000    0.000    0.000 _parallel_backends.py:185(in_main_thread)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:200(effective_n_jobs)\n",
      "        1    0.000    0.000    0.611    0.611 _parallel_backends.py:206(apply_async)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:213(get_nested_backend)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:227(effective_n_jobs)\n",
      "        4    0.000    0.000    0.000    0.000 _parallel_backends.py:280(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 _parallel_backends.py:34(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:389(configure)\n",
      "        2    0.000    0.000    0.000    0.000 _parallel_backends.py:501(effective_n_jobs)\n",
      "        1    0.000    0.000    0.611    0.611 _parallel_backends.py:569(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:574(get)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:609(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:70(configure)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:80(start_call)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:83(stop_call)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:86(terminate)\n",
      "        2    0.000    0.000    0.000    0.000 _parallel_backends.py:89(compute_batch_size)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:93(batch_completed)\n",
      "        1    2.270    2.270   33.737   33.737 _t_sne.py:445(trustworthiness)\n",
      "        1    0.000    0.000    0.000    0.000 _unsupervised.py:128(__init__)\n",
      "        1    0.000    0.000    0.026    0.026 _unsupervised.py:151(fit)\n",
      "        8    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
      "     15/7    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:1205(isspmatrix)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:345(_more_tags)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:348(_get_tags)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:359(_check_n_features)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:405(_check_feature_names)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:495(_validate_data)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:986(_more_tags)\n",
      "        1    0.000    0.000    0.000    0.000 context.py:233(get_context)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:102(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:130(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:139(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:279(helper)\n",
      "        1    0.000    0.000    0.000    0.000 disk.py:42(memstr_to_bytes)\n",
      "        5    0.000    0.000    0.000    0.000 einsumfunc.py:989(_einsum_dispatcher)\n",
      "        1    0.000    0.000    0.002    0.002 einsumfunc.py:997(einsum)\n",
      "        1    2.635    2.635    2.635    2.635 extmath.py:119(safe_sparse_dot)\n",
      "        1    0.000    0.000    0.002    0.002 extmath.py:50(row_norms)\n",
      "        4    0.000    0.000    0.004    0.001 extmath.py:870(_safe_accumulator_op)\n",
      "        1    0.000    0.000    0.000    0.000 fixes.py:100(delayed_function)\n",
      "        1    0.000    0.000    0.000    0.000 fixes.py:110(__init__)\n",
      "        1    0.000    0.000    0.611    0.611 fixes.py:115(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 fixes.py:97(delayed)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1002(_argsort_dispatcher)\n",
      "        1    0.000    0.000   25.814   25.814 fromnumeric.py:1006(argsort)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:193(_reshape_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:198(reshape)\n",
      "        5    0.000    0.000    0.000    0.000 fromnumeric.py:2118(_sum_dispatcher)\n",
      "        5    0.000    0.000    0.004    0.001 fromnumeric.py:2123(sum)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2362(_all_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2367(all)\n",
      "        2    0.000    0.000   25.814   12.907 fromnumeric.py:51(_wrapfunc)\n",
      "        6    0.000    0.000    0.004    0.001 fromnumeric.py:69(_wrapreduction)\n",
      "        6    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        2    0.000    0.000    0.000    0.000 index_tricks.py:774(_fill_diagonal_dispatcher)\n",
      "        2    0.002    0.001    0.002    0.001 index_tricks.py:778(fill_diagonal)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:606(getmro)\n",
      "        1    0.000    0.000    0.000    0.000 logger.py:23(_squeeze_time)\n",
      "        1    0.000    0.000    0.000    0.000 logger.py:39(short_format_time)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:1071(copyto)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:148(concatenate)\n",
      "        1    0.000    0.000    0.001    0.001 numeric.py:289(full)\n",
      "        8    0.000    0.000    0.000    0.000 numerictypes.py:284(issubclass_)\n",
      "        4    0.000    0.000    0.000    0.000 numerictypes.py:358(issubdtype)\n",
      "        1    0.000    0.000    5.008    5.008 pairwise.py:1521(_parallel_pairwise)\n",
      "        1    0.000    0.000    5.008    5.008 pairwise.py:1831(pairwise_distances)\n",
      "        1    0.000    0.000    5.008    5.008 pairwise.py:226(euclidean_distances)\n",
      "        1    2.367    2.367    5.005    5.005 pairwise.py:333(_euclidean_distances)\n",
      "        2    0.000    0.000    0.000    0.000 pairwise.py:39(_return_float_dtype)\n",
      "        1    0.000    0.000    0.004    0.004 pairwise.py:63(check_pairwise_arrays)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:184(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:216(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:219(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:222(unregister)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:245(__init__)\n",
      "        1    0.000    0.000    0.611    0.611 parallel.py:258(__call__)\n",
      "        1    0.000    0.000    0.611    0.611 parallel.py:262(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 parallel.py:275(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:345(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:350(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 parallel.py:385(effective_n_jobs)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:639(__init__)\n",
      "      2/1    0.000    0.000    0.000    0.000 parallel.py:732(_initialize_backend)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:757(_terminate_backend)\n",
      "        4    0.000    0.000    0.000    0.000 parallel.py:76(get_active_backend)\n",
      "        1    0.000    0.000    0.611    0.611 parallel.py:761(_dispatch)\n",
      "        2    0.000    0.000    0.611    0.306 parallel.py:798(dispatch_one_batch)\n",
      "        2    0.000    0.000    0.000    0.000 parallel.py:864(_print)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:877(print_progress)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:920(retrieve)\n",
      "        1    0.000    0.000    0.612    0.612 parallel.py:960(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 process.py:198(daemon)\n",
      "        2    0.000    0.000    0.000    0.000 process.py:37(current_process)\n",
      "        1    0.780    0.780   34.516   34.516 quality_metrics.py:45(_return_trustworthiness)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:122(put)\n",
      "        3    0.000    0.000    0.000    0.000 queue.py:154(get)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:206(_init)\n",
      "        3    0.000    0.000    0.000    0.000 queue.py:209(_qsize)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:213(_put)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:217(_get)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:34(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:218(_vhstack_dispatcher)\n",
      "        1    0.000    0.000    0.001    0.001 shape_base.py:222(vstack)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:77(_atleast_2d_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:81(atleast_2d)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1423(current_thread)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:236(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:264(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:267(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:279(_is_owned)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:359(notify)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:90(RLock)\n",
      "        1    0.000    0.000    0.000    0.000 uuid.py:138(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 uuid.py:333(hex)\n",
      "        1    0.000    0.000    0.000    0.000 uuid.py:713(uuid4)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:1276(check_is_fitted)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:1340(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:1824(_get_feature_names)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:257(_num_features)\n",
      "        4    0.000    0.000    0.000    0.000 validation.py:310(_num_samples)\n",
      "        4    0.000    0.000    0.000    0.000 validation.py:561(_ensure_no_complex_data)\n",
      "        4    0.000    0.000    0.000    0.000 validation.py:571(_check_estimator_name)\n",
      "        4    0.000    0.000    0.005    0.001 validation.py:619(check_array)\n",
      "        4    0.000    0.000    0.004    0.001 validation.py:93(_assert_all_finite)\n",
      "        4    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\n",
      "        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
      "        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "     15/7    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000   34.516   34.516 {built-in method builtins.exec}\n",
      "       37    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "       58    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       59    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt.urandom}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "        4    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\n",
      "        1    0.002    0.002    0.002    0.002 {built-in method numpy.core._multiarray_umath.c_einsum}\n",
      "    15/13    0.002    0.000   25.824    1.986 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1   25.814   25.814   25.814   25.814 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       15    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "        1    0.610    0.610    0.611    0.611 {method 'query' of 'sklearn.neighbors._kd_tree.BinaryTree' objects}\n",
      "        6    0.004    0.001    0.004    0.001 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"evaluate._return_trustworthiness(sampled_cd,sampled_embedded)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellDynCluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5deb914aa631c094dbee2b245fe292bd804ba18ca3cb2d31e687d93fc90e2ee0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
